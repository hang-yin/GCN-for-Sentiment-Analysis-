{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cosmetic-atlantic",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-investigator",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-anxiety",
   "metadata": {},
   "source": [
    "To explore dependency parsing for sentences so that word level graphs can be constructed for the problem of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-clearance",
   "metadata": {},
   "source": [
    "1. Explore how dependency parsing works\n",
    "2. Tokenize sentences and give them to the dependency parser\n",
    "3. Obtain the relationships and check them\n",
    "4. Convert the dependency graphs from the parser into the graphs that can be used for GCN\n",
    "5. Explore GCN and try to build graphs from the parsed dependency graphs\n",
    "6. Perform graph level classification\n",
    "7. Check performance\n",
    "8. Refine the various layers and hyperparameters in the process\n",
    "9. Check final performance\n",
    "10. Do interpreation manually on some selected examples\n",
    "11. Implement edge masking to get the minimum subgraph\n",
    "12. Performe automatic interpretation of the graphs to determine the most important terms/relationships for each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-internship",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-gross",
   "metadata": {},
   "source": [
    "* For dependency parsing, we will try to use the tools from the stanford nlp group.\n",
    "* The *[CoreNLP](https://github.com/stanfordnlp/CoreNLP)* library is important as it contains many of the tools needed to performe dependency parsing\n",
    "* The *[stanza](https://github.com/stanfordnlp/stanza)* library offers a wrapped version of CoreNLP that works directly with Python\n",
    "* Visualization of the graphs can be done using *[networkx](https://github.com/networkx/networkx)*\n",
    "* For GCN and word-level graphs we will primarily look at the ideas in this *[tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html)*\n",
    "* We will try to use the *[spektral](https://github.com/danielegrattarola/spektral/)* library to implement the graphs convolution and attention \n",
    "* *[Link](https://universaldependencies.org/u/dep/)* to explaination of dependency relations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-beijing",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-graphics",
   "metadata": {},
   "source": [
    "The dataset is still IMDB review but we may expand later on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-kernel",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-supervisor",
   "metadata": {},
   "source": [
    "Fill in later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-motel",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-morocco",
   "metadata": {},
   "source": [
    "Fill in at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-colonial",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-excitement",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import stanza\n",
    "import networkx as nx\n",
    "import spacy\n",
    "import stanzaTools\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-thong",
   "metadata": {},
   "source": [
    "## Part 1: Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-consideration",
   "metadata": {},
   "source": [
    "### Testing Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSentence = \"There is nothing wrong with Apple's new M1 Max Chip, everything works so well! Ok this might be kind of difficult.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    'en',\n",
    "    processors = 'tokenize,mwt,pos,lemma,depparse, sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sampleSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-recorder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = doc.sentences[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-token",
   "metadata": {},
   "source": [
    "#### tokenRelationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzaTools.tokenRelationHead(sent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-sight",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### getNodeEdgeLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeList, edgeList = stanzaTools.getNodeEdgeLists(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-cocktail",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-transcript",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodeList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-joint",
   "metadata": {},
   "source": [
    "#### drawDepGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzaTools.drawDepGraph(nodeList, edgeList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-lewis",
   "metadata": {},
   "source": [
    "### Testing Spacy (Ignore for Now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = sampleSentence\n",
    "doc = nlp(text)\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-circus",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spacy.displacy.render(doc, style='dep', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-capture",
   "metadata": {},
   "source": [
    "### Testing TF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import tfDatasetTools\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS = tfds.load('imdb_reviews', split='train', as_supervised=True, shuffle_files=True)\n",
    "testDS = tfds.load('imdb_reviews', split='test', as_supervised=True, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = testDS.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-style",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### decodeZeroDimTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-cause",
   "metadata": {},
   "source": [
    "#### convertTakeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = tfDatasetTools.convertTakeDataset(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    'en',\n",
    "    processors = 'tokenize,mwt,pos,lemma,depparse, sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-literacy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(features[1])\n",
    "for sentence in doc.sentences:\n",
    "    print(sentence.text)\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-triple",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc.sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-reply",
   "metadata": {},
   "source": [
    "### Testing spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spektral\n",
    "from spektral.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset('PROTEINS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datset = dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datset = dataset[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from spektral.layers import GCNConv, GlobalSumPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstGNN(Model):\n",
    "\n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense = Dense(n_labels, 'softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.graph_conv(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dense(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyFirstGNN(32, dataset.n_labels)\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import BatchLoader\n",
    "\n",
    "loader = BatchLoader(train_datset, batch_size=32)\n",
    "testLoader = BatchLoader(test_datset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(loader.load(),steps_per_epoch=loader.steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testLoader.load(),steps=testLoader.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datset[12].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-cooler",
   "metadata": {},
   "source": [
    "## Part 2: Graph Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-explanation",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funky-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import stanza\n",
    "import networkx as nx\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "graphic-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanzaTools\n",
    "import tfDatasetTools\n",
    "import relationEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997bbbb6-e771-491c-98e4-a105cf1063a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, time, joblib, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-newfoundland",
   "metadata": {},
   "source": [
    "### Set up Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "applied-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed7978f934e4ae490954c8ceedc0eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:48:59 INFO: Downloading default packages for language: en (English)...\n",
      "2022-05-30 22:48:59 INFO: File exists: /Users/zeyuyang/stanza_resources/en/default.zip\n",
      "2022-05-30 22:49:02 INFO: Finished downloading models and saved to /Users/zeyuyang/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e0d5d9ca3845259884b9ada179eb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:49:10 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-05-30 22:49:11 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2022-05-30 22:49:11 INFO: Use device: cpu\n",
      "2022-05-30 22:49:11 INFO: Loading: tokenize\n",
      "2022-05-30 22:49:11 INFO: Loading: pos\n",
      "2022-05-30 22:49:11 INFO: Loading: lemma\n",
      "2022-05-30 22:49:11 INFO: Loading: depparse\n",
      "2022-05-30 22:49:11 INFO: Loading: sentiment\n",
      "2022-05-30 22:49:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    'en',\n",
    "    processors = 'tokenize,mwt,pos,lemma,depparse, sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-coordinator",
   "metadata": {},
   "source": [
    "#### createGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tfDatasetTools' from '/Users/zeyuyang/Projects/CS397Project/tfDatasetTools.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(stanzaTools)\n",
    "reload(tfDatasetTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034e37c7-eb6d-46d6-a4e4-d43ebff3e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationsDict = relationEncoder.getRelationsDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "cooked-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(doc, positive):\n",
    "    startTime = time.perf_counter()\n",
    "    nodeList, edgeList = stanzaTools.getNodeEdgeLists(doc)\n",
    "    nodeTime = time.perf_counter()\n",
    "    words = [item['text'] for item in nodeList]\n",
    "    convertedFeatures = stanzaTools.convertToEmbedding(words, preprocessor, encoder)\n",
    "    adjacencyMatrix = stanzaTools.createAdjacencyMatrix(edgeList, len(nodeList))\n",
    "    convertTime = time.perf_counter()\n",
    "    sortedList = sorted(edgeList, key=lambda x: (x['edgePair'][0], x['edgePair'][1]))\n",
    "    edgeFeatures = relationEncoder.OneHotEncode(relationsDict, [edge['edgeLabel'] for edge in sortedList])\n",
    "    encodeTime = time.perf_counter()\n",
    "    label = np.array([positive])\n",
    "    print([nodeTime - startTime, convertTime  - nodeTime, encodeTime - convertTime])\n",
    "    # newGraph = spektral.data.graph.Graph(x=convertedFeatures, a=adjacencyMatrix, y=label)\n",
    "    return (convertedFeatures, adjacencyMatrix, edgeFeatures, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "7e5f7749-1850-4fe2-9614-8c27453f2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustomGraph(doc, positive):\n",
    "    startTime = time.perf_counter()\n",
    "    nodeList, edgeList = stanzaTools.getNodeEdgeLists(doc)\n",
    "    nodeTime = time.perf_counter()\n",
    "    words = [item['text'] for item in nodeList]\n",
    "    convertedFeatures = stanzaTools.convertToCustomEmbedding(words, preprocessor, model.layers[2])\n",
    "    adjacencyMatrix = stanzaTools.createAdjacencyMatrix(edgeList, len(nodeList))\n",
    "    convertTime = time.perf_counter()\n",
    "    sortedList = sorted(edgeList, key=lambda x: (x['edgePair'][0], x['edgePair'][1]))\n",
    "    edgeFeatures = relationEncoder.OneHotEncode(relationsDict, [edge['edgeLabel'] for edge in sortedList])\n",
    "    encodeTime = time.perf_counter()\n",
    "    label = np.array([positive])\n",
    "    print([nodeTime - startTime, convertTime  - nodeTime, encodeTime - convertTime])\n",
    "    # newGraph = spektral.data.graph.Graph(x=convertedFeatures, a=adjacencyMatrix, y=label)\n",
    "    return (convertedFeatures, adjacencyMatrix, edgeFeatures, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "bd7e7565-baab-4587-95df-95537e210118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustomGraph2(doc, positive):\n",
    "    startTime = time.perf_counter()\n",
    "    nodeList, edgeList = stanzaTools.getNodeEdgeLists(doc)\n",
    "    nodeTime = time.perf_counter()\n",
    "    words = [item['text'] for item in nodeList]\n",
    "    print(len(words))\n",
    "    convertedFeatures = convertToCustomEmbedding(words)\n",
    "    adjacencyMatrix = stanzaTools.createAdjacencyMatrix(edgeList, len(nodeList))\n",
    "    convertTime = time.perf_counter()\n",
    "    sortedList = sorted(edgeList, key=lambda x: (x['edgePair'][0], x['edgePair'][1]))\n",
    "    edgeFeatures = relationEncoder.OneHotEncode(relationsDict, [edge['edgeLabel'] for edge in sortedList])\n",
    "    encodeTime = time.perf_counter()\n",
    "    label = np.array([positive])\n",
    "    print([nodeTime - startTime, convertTime  - nodeTime, encodeTime - convertTime])\n",
    "    # newGraph = spektral.data.graph.Graph(x=convertedFeatures, a=adjacencyMatrix, y=label)\n",
    "    return (convertedFeatures, adjacencyMatrix, edgeFeatures, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4893d85-fbd9-469c-a19a-8d6dced0947a",
   "metadata": {},
   "source": [
    "#### createGraphAlpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a1a6c2-f837-43d0-ac9e-1f1519f5ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraphAlpha(doc, positive):\n",
    "    # startTime = time.perf_counter()\n",
    "    nodeList, edgeList = stanzaTools.getNodeEdgeLists(doc)\n",
    "    # nodeTime = time.perf_counter()\n",
    "    words = [item['text'] for item in nodeList]\n",
    "    # print(len(words))\n",
    "    convertedFeatures = convertToCustomEmbedding(words)\n",
    "    adjacencyMatrix = stanzaTools.createAdjacencyMatrix(edgeList, len(nodeList))\n",
    "    # convertTime = time.perf_counter()\n",
    "    sortedList = sorted(edgeList, key=lambda x: (x['edgePair'][0], x['edgePair'][1]))\n",
    "    edgeFeatures = relationEncoder.OneHotEncode(relationsDict, [edge['edgeLabel'] for edge in sortedList])\n",
    "    # encodeTime = time.perf_counter()\n",
    "    label = np.array([positive])\n",
    "    # print([nodeTime - startTime, convertTime  - nodeTime, encodeTime - convertTime])\n",
    "    # newGraph = spektral.data.graph.Graph(x=convertedFeatures, a=adjacencyMatrix, y=label)\n",
    "    return (convertedFeatures, adjacencyMatrix, edgeFeatures, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-enough",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "native-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:49:44.292916: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-30 22:49:44.293045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "trainDS = tfds.load('imdb_reviews', split='train', as_supervised=True, shuffle_files=True)\n",
    "testDS = tfds.load('imdb_reviews', split='test', as_supervised=True, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-literacy",
   "metadata": {},
   "source": [
    "#### Set a Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "neutral-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLimit = 10000\n",
    "testLimit = 10000\n",
    "\n",
    "trainSubset = trainDS.take(trainLimit)\n",
    "testSubset = testDS.take(testLimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "driven-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationSplit = 0.2\n",
    "validationIndex = int(validationSplit * trainLimit)\n",
    "\n",
    "validationSplitSubset = trainSubset.take(validationIndex)\n",
    "trainSplitSubset = trainSubset.skip(validationIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "complicated-panama",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:49:49.260810: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-30 22:49:49.771590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-05-30 22:49:49.907696: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-05-30 22:49:50.478883: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "trainFeatures, trainLabels = tfDatasetTools.convertTakeDataset(trainSplitSubset)\n",
    "valFeatures, valLabels = tfDatasetTools.convertTakeDataset(validationSplitSubset)\n",
    "testFeatures, testLabels = tfDatasetTools.convertTakeDataset(testSubset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d15ba0-9789-4540-aa32-0297f0c38359",
   "metadata": {},
   "source": [
    "##### Checking trainFeatures and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "901e073e-4306-4575-afd2-5b37da9e33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd3bdee93364541bd830cb76bd0870b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:49:52 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "WARNING:stanza:Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-05-30 22:49:52 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-05-30 22:49:52 INFO: Use device: cpu\n",
      "INFO:stanza:Use device: cpu\n",
      "2022-05-30 22:49:52 INFO: Loading: tokenize\n",
      "INFO:stanza:Loading: tokenize\n",
      "2022-05-30 22:49:52 INFO: Done loading processors!\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    'en',\n",
    "    processors = 'tokenize, mwt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312c200-058c-4dd5-8fc3-f6e840219f3d",
   "metadata": {},
   "source": [
    "#### Create Custom tokenizer\n",
    "The goal is to matche our tokenizer to the one used by stanza. The ideas is to first tokenize all of the train+validation reviews into words. Then use our own tokenizer to parse all of these words to learn what the vocabulary is. Later, we will use stanza to break each feature into a list of nodes. The list of nodes will be converted using our own tokenizer into a list of ints. The list of ints will be used to train the embedding model and to create the embeddings for the graph model.\n",
    "\n",
    "Use joblib with parallel jobs to speed up the processing by about 200%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf27551-528d-4d46-be36-8f8b039bc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStanzaProSents(features):\n",
    "    tokenizedSentences = []\n",
    "    for feature in features:\n",
    "        doc = nlp(feature)\n",
    "        for sentence in doc.sentences:\n",
    "            tokenizedSentences.append(\" \".join([item['text'] for item in sentence.to_dict()]))\n",
    "    return tokenizedSentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f677dbc-5ac6-4bf4-aa55-74540cdbb1e9",
   "metadata": {},
   "source": [
    "This takes about 42 seconds per 1000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc64ced-4588-47f4-92d9-d4705b4ed878",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/cy/9f5n2v596v59tmvv54kqf0jr0000gp/T/ipykernel_79340/1443369409.py\", line 4, in <module>\n",
      "    results = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(getStanzaProSents)(totalFeatures[i:i + step]) for i in range(0,trainLimit,step))\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/multiprocessing/pool.py\", line 765, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/multiprocessing/pool.py\", line 762, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/threading.py\", line 574, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 752, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 721, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/inspect.py\", line 706, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/zeyuyang/miniforge3/envs/graphLearning/lib/python3.9/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/var/folders/cy/9f5n2v596v59tmvv54kqf0jr0000gp/T/ipykernel_79340/1443369409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotalFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainFeatures\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetStanzaProSents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/graphLearning/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "step = 50\n",
    "totalFeatures = trainFeatures + valFeatures\n",
    "results = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(getStanzaProSents)(totalFeatures[i:i + step]) for i in range(0,trainLimit,step))\n",
    "print(time.perf_counter()-startTime)\n",
    "deListed = []\n",
    "for i in results:\n",
    "    deListed += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alien-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "customTokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=30000, oov_token='OOVTOKEN', filters='', lower = True, split = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "c878ce1f-4829-44c0-a1dc-bd195fa2dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customTokenizer.fit_on_texts(deListed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a70b9fd-3402-4466-91f1-e702dc674753",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './tokenizer/token' + str(trainLimit) + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "3ab6d40a-20a1-4f55-9e34-5a21902c339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if you want to rewrite the file\n",
    "tokenizer_json = customTokenizer.to_json()\n",
    "with io.open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "844e759c-4ff8-46f1-ac80-9a97796e5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "            customTokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b16cdd1-f7f2-47ea-b6d3-4c6cf37235de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54970"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(customTokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c67646-8241-4c25-8ab4-3019e53f34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = customTokenizer.texts_to_sequences([trainFeatures[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d97f311-ca2c-49e3-bc4e-fbb132862c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i love this OOVTOKEN every time i watch an episode i repeat that line and remind myself how good of a show this OOVTOKEN i am a huge sci-fi fan and this show has grounds to be the most important science OOVTOKEN show in the history of OOVTOKEN there are so many theories in this show about the universe i could start a OOVTOKEN its OOVTOKEN season after season the show gets better and OOVTOKEN i've been a fan of macgyver since i was 5 OOVTOKEN OOVTOKEN and i find it so ironic that my 2 favorite tv shows of all time star richard dean OOVTOKEN its also interesting how each character is practically the opposite of the OOVTOKEN back when i first saw stargate the OOVTOKEN i instantly liked it and considered it one of my favorite sci-fi OOVTOKEN then hearing a tv show would spin from it i got really OOVTOKEN but didn't get showtime till the fifth season was almost OOVTOKEN OOVTOKEN i'm disappointed to hear that roland emmerich and dean devlin wanted to do a trilogy of movies but the studio optioned the series OOVTOKEN id say though that it turned out just OOVTOKEN maybe even OOVTOKEN this show is OOVTOKEN and i hope it never OOVTOKEN atlantis here we OOVTOKEN\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customTokenizer.sequences_to_texts(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eee01-a278-45ff-89f9-6024ace307c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dependent-paper",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "current-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "multiple-distributor",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 23:02:06.956843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and encode input\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "\n",
    "preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2',trainable=False)\n",
    "\n",
    "outputs = encoder(encoder_inputs)\n",
    "\n",
    "pooled_output = outputs['pooled_output'] # [batch_size, 128].\n",
    "# [batch_size, seq_length, 128].\n",
    "\n",
    "sequence_output = outputs['sequence_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-industry",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sample Convert to BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "major-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 23:02:11.958773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-29 23:02:12.132296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "text = \"hello there who are you hello there who are you hello there who are you hello there who are you hello there who are you hello there who are you\"\n",
    "words = text.split()\n",
    "converted = stanzaTools.convertToEmbedding(words, preprocessor, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "light-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 128)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "coordinate-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = stanzaTools.convertToEmbedding(['!'], preprocessor, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "international-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['hello', 'there']\n",
    "convertedWords = stanzaTools.convertToEmbedding(word, preprocessor, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "recorded-dealer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertedWords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fa0e0-afc6-4610-b067-75aee0f31322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da6de07d-5213-43a9-8165-75357ad7b281",
   "metadata": {},
   "source": [
    "#### Training Custom Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d67db5-e0f4-4c70-b0b7-3e1efff2ffaf",
   "metadata": {},
   "source": [
    "Tokenize and pad the train and val features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a783f22-033d-4846-a666-4cfa3b01e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cd8d724-0db9-4061-8c66-47e4bcd31511",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7127cd8a-7599-402d-ba66-7f06c43dac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = customTokenizer.texts_to_sequences(trainFeatures)\n",
    "xTrain = pad_sequences(xTrain, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3570a95-3cc4-4e31-832d-ae1b45fa57f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 128)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "yTrain = np.array(trainLabels)\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87bd63ca-cfb3-410f-8e67-f986ecefdb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "xValidation = customTokenizer.texts_to_sequences(valFeatures)\n",
    "xValidation = pad_sequences(xValidation, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e1a8bf1-c716-4ad6-a6fc-394e629f81d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "yValidation = np.array(valLabels)\n",
    "print(xValidation.shape)\n",
    "print(yValidation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf25d1c1-01c0-414b-ae91-9ab6b2dabe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLimit = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c7c662b-644f-45e1-b7e6-f29f253b19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = customTokenizer.texts_to_sequences(testFeatures[0:testLimit])\n",
    "xTest = pad_sequences(xTest, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89556f98-b688-4503-945b-0e7af5337d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 128)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "yTest = np.array(testLabels[0:testLimit])\n",
    "print(xTest.shape)\n",
    "print(yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecae2e5-794f-40dc-a1b1-97432df859fa",
   "metadata": {},
   "source": [
    "Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "front-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleModel():\n",
    "    sequence_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedding_layer = tf.keras.layers.Embedding(30000,\n",
    "                                                10)(sequence_input)\n",
    "    pool = tf.keras.layers.GlobalAveragePooling1D()(embedding_layer)\n",
    "    # flatten = tf.keras.layers.Flatten()(embedding_layer)\n",
    "    dense_layer = tf.keras.layers.Dense(16, activation='relu')(pool)\n",
    "    outputs = tf.keras.layers.Dense(1)(dense_layer)\n",
    "\n",
    "    return tf.keras.Model(inputs=sequence_input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "preliminary-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 128, 10)           300000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 10)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                176       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 300,193\n",
      "Trainable params: 300,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "embeddingModel = sampleModel()\n",
    "embeddingModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beginning-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingModel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "recreational-buffalo",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/250 [..............................] - ETA: 1:13 - loss: 0.6922 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:52:18.809617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/250 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.5003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:52:21.457625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 3s 11ms/step - loss: 0.6793 - accuracy: 0.4994 - val_loss: 0.6451 - val_accuracy: 0.5015\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.5455 - accuracy: 0.6828 - val_loss: 0.4950 - val_accuracy: 0.7395\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3775 - accuracy: 0.8434 - val_loss: 0.4183 - val_accuracy: 0.7990\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.2775 - accuracy: 0.8918 - val_loss: 0.3956 - val_accuracy: 0.8145\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.2110 - accuracy: 0.9235 - val_loss: 0.3931 - val_accuracy: 0.8205\n"
     ]
    }
   ],
   "source": [
    "history = embeddingModel.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    validation_data=(xValidation, yValidation),\n",
    "    epochs=5,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beneficial-gates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.8076\n"
     ]
    }
   ],
   "source": [
    "results = embeddingModel.evaluate(x=xTest, y=yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30a116-776f-4498-b2fe-ea66a1e1b664",
   "metadata": {},
   "source": [
    "##### Sample Convert to Custom Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c2ec222-b641-48ac-84ff-ebd6cfcb9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x297d18fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingModel.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de036072-ea80-4f9f-bce5-0c2bad2a7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfWords = \"why did I do this\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2ac64d6-2d10-4747-a55a-054aafab98a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why', 'did', 'I', 'do', 'this']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a85901d-ad74-45c2-a780-a370fc904d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = customTokenizer.texts_to_sequences(listOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dca0d1fd-aea6-4b8b-9c5b-580fe65d166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[149], [82], [12], [49], [13]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d93ba14-5113-4b8a-8c82-578f76a504fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedSeq = np.array(sequence).reshape((len(sequence),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70c75abd-1bd9-4475-87b1-3a47b5c8bbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149,  82,  12,  49,  13])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshapedSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7da9733-e41b-4727-9373-b1b8c883cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddedSeq = embeddingModel.layers[1](reshapedSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f638bb85-6c2f-4396-9b96-98f30be6548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14898784, -0.2015486 ,  0.1545174 , -0.20380849,  0.13972424,\n",
       "        -0.15702944, -0.18963473, -0.18370965, -0.1568994 ,  0.18087405],\n",
       "       [ 0.05457168, -0.0051488 ,  0.04195864, -0.04556615,  0.08350474,\n",
       "        -0.01199649, -0.03057951, -0.19082686, -0.09691024,  0.04957812],\n",
       "       [-0.04589343,  0.02158026, -0.00656239,  0.0094852 ,  0.01542812,\n",
       "         0.01383816, -0.05389365, -0.40174693, -0.03835957,  0.00947896],\n",
       "       [ 0.14888184, -0.18132693,  0.1872304 , -0.14353447,  0.17850393,\n",
       "        -0.11974902, -0.17311119, -0.31304327, -0.12161618,  0.13498373],\n",
       "       [-0.00481547,  0.03384902,  0.02145714, -0.00612692, -0.00988518,\n",
       "         0.04158428, -0.09429195, -0.40252402, -0.01765343, -0.00158498]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embeddedSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe2c4a-9b57-4e3c-9c6f-44a8e10f1a0b",
   "metadata": {},
   "source": [
    "#### convertToCustomEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "064c2287-09f2-4b1f-9851-5b5001d1fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCustomEmbedding(words):\n",
    "    \"\"\"\n",
    "    Takes a list of words and converts it to a list of custom embeddings. \n",
    "\n",
    "    Args:\n",
    "        words - (list) The list of words to convert\n",
    "    Returns:\n",
    "        embeddings - (list) A list of embeddings\n",
    "    \"\"\"\n",
    "    sequence = customTokenizer.texts_to_sequences(words)\n",
    "    reshapedSeq = np.array(sequence).reshape((len(sequence),))\n",
    "    convertedWords = embeddingModel.layers[1](reshapedSeq)\n",
    "    return np.array(convertedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-application",
   "metadata": {},
   "source": [
    "### Convert Data to Graph Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44add8bb-6a06-4095-87d9-65c7abf300cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6ffbb0a4a544e280fb98b775772f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:52:52 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "WARNING:stanza:Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-05-30 22:52:53 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2022-05-30 22:52:53 INFO: Use device: cpu\n",
      "INFO:stanza:Use device: cpu\n",
      "2022-05-30 22:52:53 INFO: Loading: tokenize\n",
      "INFO:stanza:Loading: tokenize\n",
      "2022-05-30 22:52:53 INFO: Loading: pos\n",
      "INFO:stanza:Loading: pos\n",
      "2022-05-30 22:52:53 INFO: Loading: lemma\n",
      "INFO:stanza:Loading: lemma\n",
      "2022-05-30 22:52:53 INFO: Loading: depparse\n",
      "INFO:stanza:Loading: depparse\n",
      "2022-05-30 22:52:53 INFO: Loading: sentiment\n",
      "INFO:stanza:Loading: sentiment\n",
      "2022-05-30 22:52:53 INFO: Done loading processors!\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    'en',\n",
    "    processors = 'tokenize,mwt,pos,lemma,depparse, sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2c8a2-1097-48bc-aea6-36d46410beab",
   "metadata": {},
   "source": [
    "#### convertToGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "8c67e0e3-9128-4d5e-bc81-67db68fd3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGraph(sentence, label):\n",
    "    doc = nlp(sentence)\n",
    "    newGraph = createGraphAlpha(doc, label)\n",
    "    return newGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "e7ff2024-50d2-4d8d-9ae1-8b88db5df1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrain = len(trainFeatures)\n",
    "numVal = len(valFeatures)\n",
    "numTest = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "468ed815-747b-4f82-9547-323549ef88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988.5259711249964\n"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "# trainGraphs = [convertToGraph(trainFeatures[i], trainLabels[i]) for i in range(10)]\n",
    "trainGraphs = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(convertToGraph)(trainFeatures[i], trainLabels[i]) for i in range(numTrain))\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "c9545999-eab0-409b-b0cd-eaceca12f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68, 10), (68, 68), (65, 51), (1,)]"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.shape for item in trainGraphs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "b7d99bb0-b8ad-4cde-93f1-df62f4eb5e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.53204129100777\n"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "validationGraphs = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(convertToGraph)(valFeatures[i], valLabels[i]) for i in range(numVal))\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "3bc551c9-a64b-46e5-b8e2-76481f3067e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36, 10), (36, 36), (33, 51), (1,)]"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.shape for item in validationGraphs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "4fa88f76-9483-4f1a-9dee-0e62cdfbbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578.1976409999916\n"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "testGraphs = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(convertToGraph)(testFeatures[i], testLabels[i]) for i in range(numTest))\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "2439caa6-d710-41cc-923e-ae09a6d5ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(83, 10), (83, 83), (78, 51), (1,)]"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.shape for item in testGraphs[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47af7b-5070-4c98-9653-cf2df26f2bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "42961004-89e0-41d7-b0fe-1ab98a98f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "for i in range(10):\n",
    "    sentence = trainFeatures[i]\n",
    "    label = trainLabels[i]\n",
    "    sentences.append(sentence)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "e87e8bbf-b5d4-4051-85d7-a2c1b6ab1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this show!  Every time i watch an episode i repeat that line and remind myself how good of a \n",
      "I gave it a 10, since everyone else seemed to like it and it would have been churlish not to. The re\n",
      "Considering its pedigree, this should be a far more enjoyable film than it is. Even with a lip-smack\n",
      "Give this movie a break! Its worth at least a \"7\"! That little girl is a good actor and she's cute, \n",
      "Actually had to stop it. Don't get me wrong, love bad monster movies. But this one was way too borin\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[0:5]:\n",
    "    print(sentence[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "d0a2cb05-a626-4d98-acae-c56e4fc8ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "9eda0e62-b80c-47b8-929d-6fff7971b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5648865830007708\n"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "docs = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    docs.append(doc)\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "285121b4-3200-4e7b-9502-4ff0d102990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this show!\n",
      "I gave it a 10, since everyone else seemed to like it and it would have been churlish not to.\n",
      "Considering its pedigree, this should be a far more enjoyable film than it is.\n",
      "Give this movie a break!\n",
      "Actually had to stop it.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[0:5]:\n",
    "    print(doc.sentences[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "2fc03d38-bc35-4a13-94b5-e872e6e61f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDepenParse(sentence):\n",
    "    return(nlp(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "767ee204-73e5-4ef0-8a21-8de58a8c766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.400063583991141\n"
     ]
    }
   ],
   "source": [
    "startTime = time.perf_counter()\n",
    "parallelDocs = joblib.Parallel(n_jobs=8, prefer=\"threads\")(joblib.delayed(nlp)(sentences[i]) for i in range(len(sentences)))\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "674476bd-77a3-4190-a1c3-0a959b6448ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this show!\n",
      "I gave it a 10, since everyone else seemed to like it and it would have been churlish not to.\n",
      "Considering its pedigree, this should be a far more enjoyable film than it is.\n",
      "Give this movie a break!\n",
      "Actually had to stop it.\n"
     ]
    }
   ],
   "source": [
    "for doc in parallelDocs[0:5]:\n",
    "    print(doc.sentences[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "51561309-1bb7-460c-843c-0fbf69cbe06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016565000114496797, 0.8239069159899373, 4.258399712853134e-05]\n",
      "[0.0005920830008108169, 0.880328291998012, 5.966699973214418e-05]\n",
      "[0.0004295000107958913, 0.5279259999952046, 4.3624997488223016e-05]\n",
      "[0.00021374999778345227, 0.1548051249992568, 2.400000812485814e-05]\n",
      "[0.0004080420039827004, 0.41955416700511705, 3.466599446255714e-05]\n",
      "[0.0003648330020951107, 0.38100525000481866, 3.6124998587183654e-05]\n",
      "[8.412500028498471e-05, 0.050149124988820404, 1.2541000614874065e-05]\n",
      "[0.00044112501200288534, 0.6078953749965876, 4.849999095313251e-05]\n",
      "[0.0008354589954251423, 1.7352896660013357, 6.474999827332795e-05]\n",
      "[0.0004531250015133992, 0.6398550419980893, 4.225000157020986e-05]\n",
      "6.228190624999115\n"
     ]
    }
   ],
   "source": [
    "performanceTest = []\n",
    "startTime = time.perf_counter()\n",
    "for i in range(len(docs)):\n",
    "    doc = docs[i]\n",
    "    label = labels[i]\n",
    "    newGraph = createGraph(doc, label)\n",
    "    performanceTest.append(newGraph)\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "8448e940-8289-41e9-a24c-ef4e81f7d5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 128)"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceTest[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "bd3d2628-c115-4d30-af0e-e6329745362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:46.623199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0014568749902537093, 0.650831000006292, 4.850000550504774e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:47.259807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000592500000493601, 1.0497337500128197, 5.037499067839235e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:48.308816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00040020800952333957, 0.6706725839903811, 4.2750005377456546e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:48.981627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0002625420020194724, 0.2348579579993384, 2.4708002456463873e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:49.218482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00036829200689680874, 0.42855179199250415, 3.783300053328276e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:49.645511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0003355830122018233, 0.39810258299985435, 3.258399374317378e-05]\n",
      "[7.166700379457325e-05, 0.10051387498970143, 1.4375007594935596e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:50.043553: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-30 20:44:50.145551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00044062500819563866, 0.6135991249902872, 4.1000006604008377e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:50.759863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0006962500046938658, 1.3325668750039767, 6.137500167824328e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:52.093539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0004484169912757352, 0.6950325420039007, 3.9165999623946846e-05]\n",
      "6.181251499991049\n"
     ]
    }
   ],
   "source": [
    "performanceCustomTest = []\n",
    "startTime = time.perf_counter()\n",
    "for i in range(len(docs)):\n",
    "    doc = docs[i]\n",
    "    label = labels[i]\n",
    "    newGraph = createCustomGraph(doc, label)\n",
    "    performanceCustomTest.append(newGraph)\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "97b37c23-798f-4d78-bf84-a9e850562730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 10)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceCustomTest[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "1ccb156d-52a6-427c-9e79-b312e4f9899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "91\n",
      "67\n",
      "29\n",
      "56\n",
      "55\n",
      "8\n",
      "69\n",
      "113\n",
      "73\n",
      "0.04741829200065695\n"
     ]
    }
   ],
   "source": [
    "performanceCustomTest2 = []\n",
    "startTime = time.perf_counter()\n",
    "for i in range(len(docs)):\n",
    "    doc = docs[i]\n",
    "    label = labels[i]\n",
    "    newGraph = createGraphAlpha(doc, label)\n",
    "    performanceCustomTest2.append(newGraph)\n",
    "timeElapsed = time.perf_counter() - startTime\n",
    "print(timeElapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "7b350c6e-1af5-4e56-9494-6ffcc94c4841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 10)"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceCustomTest2[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "296ada08-fc49-4037-9bee-24515cc1b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=68, n_node_features=10, n_edge_features=51, n_labels=1)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph(performanceCustomTest2[0][0], performanceCustomTest2[0][1], performanceCustomTest2[0][2], performanceCustomTest2[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "3786527c-bf19-4973-bab8-c3058f60c4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceCustomTest2[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a0cbc-80e5-42ac-abab-433212046c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-globe",
   "metadata": {},
   "source": [
    "### Custom Graph Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "stone-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import Dataset \n",
    "from spektral.data.graph import Graph\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "specified-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset of train graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # self.path = savePath\n",
    "        # self.download()\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def download(self):\n",
    "        # data = ... \n",
    "        # Download from somewhere\n",
    "\n",
    "        # Create the directory\n",
    "        try:\n",
    "            os.mkdir(self.path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Write the data to file\n",
    "        for i in range(len(trainGraphs)):\n",
    "            x = trainGraphs[i][0]\n",
    "            a = trainGraphs[i][1]\n",
    "            e = trainGraphs[i][2]\n",
    "            y = trainGraphs[i][3]\n",
    "\n",
    "            filename = os.path.join(self.path, f'graph_{i}')\n",
    "            np.savez(filename, x=x, a=a, e=e, y=y)\n",
    "            \n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        for i in range(len(trainGraphs)):\n",
    "            data = np.load(os.path.join(self.path, f'graph_{i}.npz'), allow_pickle=True)\n",
    "            # print(data['a'])\n",
    "            output.append(\n",
    "                Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "            )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "reduced-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset of val graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # self.path = savePath\n",
    "        # self.download()\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def download(self):\n",
    "        # data = ... \n",
    "        # Download from somewhere\n",
    "\n",
    "        # Create the directory\n",
    "        try:\n",
    "            os.mkdir(self.path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Write the data to file\n",
    "        for i in range(len(validationGraphs)):\n",
    "            x = validationGraphs[i][0]\n",
    "            a = validationGraphs[i][1]\n",
    "            e = validationGraphs[i][2]\n",
    "            y = validationGraphs[i][3]\n",
    "\n",
    "            filename = os.path.join(self.path, f'graph_val_{i}')\n",
    "            np.savez(filename, x=x, a=a, e=e, y=y)\n",
    "            \n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        for i in range(len(validationGraphs)):\n",
    "            data = np.load(os.path.join(self.path, f'graph_val_{i}.npz'), allow_pickle=True)\n",
    "            # print(data['a'])\n",
    "            output.append(\n",
    "                Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "            )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c050412f-d9d1-45ee-92ba-460dcabd0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset of val graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # self.download()\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def download(self):\n",
    "        # data = ... \n",
    "        # Download from somewhere\n",
    "\n",
    "        # Create the directory\n",
    "        try:\n",
    "            os.mkdir(self.path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Write the data to file\n",
    "        for i in range(len(testGraphs)):\n",
    "            x = testGraphs[i][0]\n",
    "            a = testGraphs[i][1]\n",
    "            e = testGraphs[i][2]\n",
    "            y = testGraphs[i][3]\n",
    "\n",
    "            filename = os.path.join(self.path, f'graph_test_{i}')\n",
    "            np.savez(filename, x=x, a=a, e=e, y=y)\n",
    "            \n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        for i in range(len(testGraphs)):\n",
    "            data = np.load(os.path.join(self.path, f'graph_test_{i}.npz'), allow_pickle=True)\n",
    "            # print(data['a'])\n",
    "            output.append(\n",
    "                Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "            )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0694682e-db68-4ccb-ace1-fe3dd995cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadValGraph(graphDir, index):\n",
    "    data = np.load(os.path.join(graphDir, f'graph_val_{index}.npz'), allow_pickle=True)\n",
    "    graph = Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "    return graph\n",
    "\n",
    "def loadTrainGraph(graphDir, index):\n",
    "    data = np.load(os.path.join(graphDir, f'graph_{index}.npz'), allow_pickle=True)\n",
    "    graph = Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "    return graph\n",
    "\n",
    "def loadTestGraph(graphDir, index):\n",
    "    data = np.load(os.path.join(graphDir, f'graph_test_{index}.npz'), allow_pickle=True)\n",
    "    graph = Graph(x=data['x'], a=data['a'], e=data['e'], y=data['y'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ecb711e-a662-4a23-bd35-0945506a9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load prev generated val graphs\n",
    "valGraphDir = '/Users/zeyuyang/spektral/datasets/ValDataset'\n",
    "valGraphNum = 2000\n",
    "validationGraphs = [loadValGraph(valGraphDir, i) for i in range(valGraphNum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sophisticated-reservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValDataset(n_graphs=2000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valDataset = ValDataset()\n",
    "valDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e3d4798-6934-4195-bf50-715b56f00961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=36, n_node_features=10, n_edge_features=51, n_labels=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdffbbdd-01ec-4876-8f1c-c6f6b59fd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load prev generated train graphs\n",
    "trainGraphDir = '/Users/zeyuyang/spektral/datasets/TrainDataset'\n",
    "trainGraphNum = 8000\n",
    "trainGraphs = [loadTrainGraph(trainGraphDir, i) for i in range(trainGraphNum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "amateur-district",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainDataset(n_graphs=8000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset = TrainDataset()\n",
    "trainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d530ec5-521d-488b-804b-d87ef9b7cb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=68, n_node_features=10, n_edge_features=51, n_labels=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2ed12af-6705-44b6-b6bb-78712bb3893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load prev generated test graphs\n",
    "testGraphDir = '/Users/zeyuyang/spektral/datasets/TestDataset'\n",
    "testGraphNum = 5000\n",
    "testGraphs = [loadTestGraph(testGraphDir, i) for i in range(testGraphNum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76a64e13-9c98-4ba3-838f-a1a510295eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestDataset(n_graphs=5000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset = TestDataset()\n",
    "testDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "522b3c18-2f7c-4c7d-9a51-3e396e7f8fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=83, n_node_features=10, n_edge_features=51, n_labels=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-alexander",
   "metadata": {},
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "brave-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Embedding\n",
    "from spektral.layers import GCNConv, GlobalSumPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "advance-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstGNN(Model):\n",
    "\n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        self.graph_conv2 = GCNConv(n_hidden)\n",
    "        self.graph_conv3 = GCNConv(n_hidden)\n",
    "        self.graph_conv4 = GCNConv(4)\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.AGNNCONV = spektral.layers.AGNNConv(trainable=True, aggregate='sum', activation=None)\n",
    "        self.GenConv = spektral.layers.GeneralConv(channels=n_hidden, batch_norm=True, dropout=0.0,\n",
    "                                                   aggregate='sum', activation='prelu', use_bias=True,\n",
    "                                                   kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "                                                   kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "                                                   kernel_constraint=None, bias_constraint=None)\n",
    "        self.graphAtten = spektral.layers.GATConv(channels=n_hidden, attn_heads=5,\n",
    "                                                  concat_heads=True, dropout_rate=0.2, return_attn_coef=False,\n",
    "                                                  add_self_loops=True, activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                                                  bias_initializer='zeros', attn_kernel_initializer='glorot_uniform', kernel_regularizer=None,\n",
    "                                                  bias_regularizer=None, attn_kernel_regularizer=None, activity_regularizer=None,\n",
    "                                                  kernel_constraint=None, bias_constraint=None, attn_kernel_constraint=None)\n",
    "        self.graphECC = spektral.layers.ECCConv(channels=n_hidden, kernel_network=None, root=True, activation=None, use_bias=True,\n",
    "                                                kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None,\n",
    "                                                bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "                                                bias_constraint=None)\n",
    "        self.maxPool = spektral.layers.GlobalMaxPool()\n",
    "        self.avePool = spektral.layers.GlobalAvgPool()\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dropout2 = Dropout(0.2)\n",
    "        self.dense2 = Dense(16, activation='relu')\n",
    "        self.dense = Dense(1, 'sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, e, i = inputs\n",
    "        # x = self.graph_conv([x,a])\n",
    "        x = self.graphECC([x,a, e])\n",
    "        # x = self.graph_conv2([x,a])\n",
    "        # x = self.graph_conv3([x,a])\n",
    "        # x = self.graph_conv4([x,a])\n",
    "        # out = self.pool(out)\n",
    "        # out = self.maxPool([x, i])\n",
    "        out = self.avePool([x, i])\n",
    "        out = self.dense1(out)\n",
    "        out = self.dropout2(out)\n",
    "        # out = self.dense2(out)\n",
    "        out = self.dense(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aboriginal-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "graphModel = MyFirstGNN(16, 1)\n",
    "graphModel.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "running-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import BatchLoader\n",
    "\n",
    "# trainLoader = BatchLoader(trainDataset, node_level=False, batch_size=10, epochs=None, shuffle=True)\n",
    "trainLoader = spektral.data.loaders.DisjointLoader(trainDataset, node_level=False, batch_size=80, epochs=None, shuffle=True)\n",
    "\n",
    "validationLoader = spektral.data.loaders.DisjointLoader(valDataset, node_level=False, batch_size=80)\n",
    "\n",
    "testLoader = spektral.data.loaders.DisjointLoader(testDataset, node_level=False, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "polished-stick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=61, n_node_features=10, n_edge_features=51, n_labels=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "average-miami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 23:30:01.943133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 23:30:43.156015: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 47s 453ms/step - loss: 0.4951 - accuracy: 0.8345 - val_loss: 0.4678 - val_accuracy: 0.7895\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 44s 440ms/step - loss: 0.3364 - accuracy: 0.8609 - val_loss: 0.4603 - val_accuracy: 0.7985\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 45s 447ms/step - loss: 0.3042 - accuracy: 0.8758 - val_loss: 0.4537 - val_accuracy: 0.7990\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 45s 454ms/step - loss: 0.2954 - accuracy: 0.8794 - val_loss: 0.4576 - val_accuracy: 0.7970\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 0.2909 - accuracy: 0.8804 - val_loss: 0.4600 - val_accuracy: 0.7980\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 47s 473ms/step - loss: 0.2905 - accuracy: 0.8785 - val_loss: 0.4556 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 47s 474ms/step - loss: 0.2875 - accuracy: 0.8818 - val_loss: 0.4714 - val_accuracy: 0.7935\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 47s 475ms/step - loss: 0.2888 - accuracy: 0.8801 - val_loss: 0.4624 - val_accuracy: 0.7970\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 49s 490ms/step - loss: 0.2875 - accuracy: 0.8810 - val_loss: 0.4613 - val_accuracy: 0.7990\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 49s 493ms/step - loss: 0.2873 - accuracy: 0.8795 - val_loss: 0.4697 - val_accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "history = graphModel.fit(trainLoader.load(),\n",
    "              validation_data=validationLoader.load(),\n",
    "              steps_per_epoch=trainLoader.steps_per_epoch,\n",
    "              validation_steps=validationLoader.steps_per_epoch,\n",
    "              epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "joined-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 14s 219ms/step - loss: 0.5008 - accuracy: 0.7890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5007709860801697, 0.7890000343322754]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphModel.evaluate(testLoader.load(), steps=testLoader.steps_per_epoch)\n",
    "# graphModel.evaluate(validationLoader.load(), steps=validationLoader.steps_per_epoch)\n",
    "# graphModel.evaluate(trainLoader.load(), steps=trainLoader.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ab1153b-83c4-4a5f-a359-a4fa3318cdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphModel.predict(trainLoader.load(), steps=trainLoader.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9cae64ca-c845-45b5-9a4a-298883a1e0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [trainGraphs[i][3] for i in range(len(trainGraphs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a650f78f-c407-4f46-a289-c4574e300b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphModel.predict(testLoader.load(), steps=testLoader.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59b2144b-1b23-4d1a-aa85-92641adac392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [validationGraphs[i][3] for i in range(len(validationGraphs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "developing-oregon",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validaiton loss over epochs\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"-r^\" is for solid red line with triangle markers.\n",
    "plt.plot(epochs, loss, '-r^', label='Training loss')\n",
    "# \"-b0\" is for solid blue line with circle markers.\n",
    "plt.plot(epochs, val_loss, '-bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e52266ee-e5ae-4465-8f19-febea0adc17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy over epochs\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, '-r^', label='Training acc')\n",
    "plt.plot(epochs, val_acc, '-bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab62280-30d1-47c1-90bc-715751c2f257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aboriginal-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "049880df-6d78-42f8-bc89-ab6890cb886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/gdb9.tar.gz\n",
      "44859392/44852087 [==============================] - 43s 1us/step\n",
      "44867584/44852087 [==============================] - 43s 1us/step\n",
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2878.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = QM9(amount=1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de0185-aef9-4da0-821e-d39b12c995f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=107, n_node_features=128, n_edge_features=None, n_labels=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
