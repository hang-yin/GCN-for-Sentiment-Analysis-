{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5f4233-f3dc-4b83-9c8e-fedafeb73041",
   "metadata": {
    "id": "bc5f4233-f3dc-4b83-9c8e-fedafeb73041"
   },
   "source": [
    "# Abstract for the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b87ce-4aba-43e4-a19a-3ef6910df878",
   "metadata": {
    "id": "793b87ce-4aba-43e4-a19a-3ef6910df878"
   },
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b3d88-211a-46a2-8029-f91ba4023be6",
   "metadata": {
    "id": "f96b3d88-211a-46a2-8029-f91ba4023be6"
   },
   "source": [
    "The task is to test which model architecture performs best at imdb sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4617e-384e-444d-97cf-663141d35e98",
   "metadata": {
    "id": "20d4617e-384e-444d-97cf-663141d35e98"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39586fc7-bdb3-41f5-af12-75a5047dec29",
   "metadata": {
    "id": "39586fc7-bdb3-41f5-af12-75a5047dec29"
   },
   "source": [
    "The models utilize BERT embeddings and various combinations of lstm , cnn , and graph techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beddffa-3a84-4c52-9f2d-7cda2ed81c95",
   "metadata": {
    "id": "2beddffa-3a84-4c52-9f2d-7cda2ed81c95"
   },
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238a08d-07a3-4bb0-881a-9b53737cc1ec",
   "metadata": {
    "id": "3238a08d-07a3-4bb0-881a-9b53737cc1ec"
   },
   "source": [
    "The experiments are in progress. We are looking for accuracy, failure points, and interpretability. The goal is to test for full data, limited data, and limited label scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cfee9-d0b0-40b5-813b-a18e39af04d9",
   "metadata": {
    "id": "017cfee9-d0b0-40b5-813b-a18e39af04d9"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f386a-76fe-4af7-911e-ad7d29cb3fac",
   "metadata": {
    "id": "cc7f386a-76fe-4af7-911e-ad7d29cb3fac"
   },
   "source": [
    "The main dataset is the IMDB movie reviews and whatever was used to produce the BERT embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7b98f-2c66-4438-8a47-2c4f8e4ddbba",
   "metadata": {
    "id": "c1b7b98f-2c66-4438-8a47-2c4f8e4ddbba"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a602346-56ca-4a16-88ce-2dc585b155f2",
   "metadata": {
    "id": "2a602346-56ca-4a16-88ce-2dc585b155f2"
   },
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "Ooc42YZHqHn8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ooc42YZHqHn8",
    "outputId": "6f7f9324-63f3-47a6-99c2-91e855abfee6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --quiet tensorflow-text==2.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ZcAQzY_YP5NJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcAQzY_YP5NJ",
    "outputId": "0dc44825-b9e0-4c4f-dc0f-4a306b1b47e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet neural_structured_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88bd8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cb8783-f4e7-4f35-8ea8-f6bc1e30584a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33cb8783-f4e7-4f35-8ea8-f6bc1e30584a",
    "outputId": "f95521e7-dbdd-46ee-b4be-9ef8a440024a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.8.2\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import neural_structured_learning as nsl\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import pandas as pd\n",
    "\n",
    "from spektral.data import Graph\n",
    "from spektral.data import Dataset\n",
    "from spektral.transforms import GCNFilter\n",
    "import pandas as pd\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.data.loaders import SingleLoader\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Resets notebook state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\n",
    "    \"GPU is\",\n",
    "    \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8w9IfyWkVmNs",
   "metadata": {
    "id": "8w9IfyWkVmNs"
   },
   "outputs": [],
   "source": [
    "# # remove directory from files\n",
    "# import shutil\n",
    "# shutil.rmtree('CS397Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "gqGaEJbuQd47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqGaEJbuQd47",
    "outputId": "bd6eacdc-70ab-469e-efcf-ea799d3d7a0c"
   },
   "outputs": [],
   "source": [
    "# use this to clone a specific branch from repo\n",
    "# !git clone https://hang-yin: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@github.com/xiaojoey/CS397Project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "iKaHFf2IQLW2",
   "metadata": {
    "id": "iKaHFf2IQLW2"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/CS397Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vECgs-urXfUm",
   "metadata": {
    "id": "vECgs-urXfUm"
   },
   "outputs": [],
   "source": [
    "import dataLoader\n",
    "import bertEmbeddings\n",
    "import tfRecordTools\n",
    "import train\n",
    "import importlib\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964ce30-7e5e-492e-86c2-e2f466d33218",
   "metadata": {
    "id": "2964ce30-7e5e-492e-86c2-e2f466d33218"
   },
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea73b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fea73b0a",
    "outputId": "731332d5-60d5-47d4-9c07-e9c5efb56ee6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\GitHub Clone\\CS397Project\\MainNotebook.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHub%20Clone/CS397Project/MainNotebook.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# Load data from IMDB\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/GitHub%20Clone/CS397Project/MainNotebook.ipynb#ch0000020?line=1'>2</a>\u001b[0m imdb \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mimdb\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHub%20Clone/CS397Project/MainNotebook.ipynb#ch0000020?line=2'>3</a>\u001b[0m (pp_train_data, pp_train_labels), (pp_test_data, pp_test_labels) \u001b[39m=\u001b[39m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHub%20Clone/CS397Project/MainNotebook.ipynb#ch0000020?line=3'>4</a>\u001b[0m     imdb\u001b[39m.\u001b[39mload_data(num_words\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data from IMDB\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(pp_train_data, pp_train_labels), (pp_test_data, pp_test_labels) = (\n",
    "    imdb.load_data(num_words=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb9bcdc9",
   "metadata": {
    "id": "cb9bcdc9"
   },
   "outputs": [],
   "source": [
    "# This block limits how much is loaded to keep debugging short\n",
    "# don't run on the final experiments\n",
    "\n",
    "limit = 20000\n",
    "\n",
    "pp_train_data = pp_train_data[0:limit]\n",
    "pp_train_labels = pp_train_labels[0:limit]\n",
    "pp_test_data = pp_test_data[0:limit]\n",
    "pp_test_labels = pp_test_labels[0:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c9d5eb4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9d5eb4e",
    "outputId": "7d7346b8-7867-4cd6-b904-0d90a527914a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print data entries\n",
    "print('Training entries: {}, labels: {}'.format(\n",
    "    len(pp_train_data),\n",
    "    len(pp_train_labels)\n",
    "))\n",
    "training_samples_count = len(pp_train_data)\n",
    "print(pp_train_data[0])\n",
    "len(pp_train_data[0]), len(pp_train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24459eb0-dc05-4fc1-9fee-9ff89dc0483b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24459eb0-dc05-4fc1-9fee-9ff89dc0483b",
    "outputId": "46287054-788b-41d9-ada8-3b7437336153"
   },
   "outputs": [],
   "source": [
    "reverseWordIndex = dataLoader.buildReverseWordIndex(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e51c324",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "8e51c324",
    "outputId": "6b7bf478-5e2c-4626-a998-739eb7d858b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.decodeReview(pp_train_data[0], reverseWordIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91262af3-e6fd-48ba-946e-0ee5371a580e",
   "metadata": {
    "id": "91262af3-e6fd-48ba-946e-0ee5371a580e"
   },
   "source": [
    "## Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00852ae7-69da-493b-ab1d-6eabe98319ba",
   "metadata": {
    "id": "00852ae7-69da-493b-ab1d-6eabe98319ba"
   },
   "outputs": [],
   "source": [
    "# Retrieve small bert embeddings\n",
    "pretrained_embedding = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c2d9317c-a174-4244-b6ef-720ff37ff31a",
   "metadata": {
    "id": "c2d9317c-a174-4244-b6ef-720ff37ff31a"
   },
   "outputs": [],
   "source": [
    "# Preprocess and encode input\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2',trainable=True)\n",
    "\n",
    "outputs = encoder(encoder_inputs)\n",
    "\n",
    "pooled_output = outputs['pooled_output'] # [batch_size, 128].\n",
    "# [batch_size, seq_length, 128].\n",
    "\n",
    "sequence_output = outputs['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1T7FSUmGrS9I",
   "metadata": {
    "id": "1T7FSUmGrS9I"
   },
   "outputs": [],
   "source": [
    "oneEmbedding = bertEmbeddings.createBertEmbeddingExample(pp_train_data[0], 0, reverseWordIndex, encoder, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e3b23e93-343d-48d8-9534-d3134fed6a40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3b23e93-343d-48d8-9534-d3134fed6a40",
    "outputId": "93ec8af8-f314-411f-a7b7-03849cd17163",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"embedding\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: -0.9970535635948181\n",
       "        value: 0.13148632645606995\n",
       "        value: -0.9839853644371033\n",
       "        value: 0.9861465096473694\n",
       "        value: -0.9971203804016113\n",
       "        value: 0.8560855984687805\n",
       "        value: -0.9944373965263367\n",
       "        value: -0.13611257076263428\n",
       "        value: -0.0335337333381176\n",
       "        value: 0.1380845159292221\n",
       "        value: -0.8371204733848572\n",
       "        value: 0.012691918760538101\n",
       "        value: -0.05454465001821518\n",
       "        value: 0.9937337040901184\n",
       "        value: -0.6224281787872314\n",
       "        value: -0.9658992290496826\n",
       "        value: 0.969678521156311\n",
       "        value: 0.005809130147099495\n",
       "        value: -0.8203678131103516\n",
       "        value: 0.979274570941925\n",
       "        value: 0.7504120469093323\n",
       "        value: 0.05522242188453674\n",
       "        value: 0.9424341320991516\n",
       "        value: 0.07357420772314072\n",
       "        value: -0.9999371767044067\n",
       "        value: -0.03137067332863808\n",
       "        value: -0.9918352365493774\n",
       "        value: 0.9417162537574768\n",
       "        value: 0.9879518747329712\n",
       "        value: 0.19298511743545532\n",
       "        value: 0.27542704343795776\n",
       "        value: 0.14537528157234192\n",
       "        value: -0.9920747876167297\n",
       "        value: -0.5646538138389587\n",
       "        value: 0.9556251764297485\n",
       "        value: 0.9966796040534973\n",
       "        value: -0.2129630595445633\n",
       "        value: -0.14163324236869812\n",
       "        value: -0.032538700848817825\n",
       "        value: -0.9948015809059143\n",
       "        value: 0.30970287322998047\n",
       "        value: 0.993799090385437\n",
       "        value: -0.9927107095718384\n",
       "        value: 0.77128005027771\n",
       "        value: -0.9788926243782043\n",
       "        value: -0.32223546504974365\n",
       "        value: -0.9982249736785889\n",
       "        value: 0.9900729656219482\n",
       "        value: 0.15506476163864136\n",
       "        value: 0.9800440669059753\n",
       "        value: 0.956933856010437\n",
       "        value: -0.9695090651512146\n",
       "        value: 0.1344425082206726\n",
       "        value: 0.9866063594818115\n",
       "        value: 0.9986726641654968\n",
       "        value: 0.9574974775314331\n",
       "        value: -0.8933831453323364\n",
       "        value: 0.6398168206214905\n",
       "        value: 0.7212494015693665\n",
       "        value: -0.9690950512886047\n",
       "        value: 0.08886722475290298\n",
       "        value: -0.4205208718776703\n",
       "        value: 0.6737985610961914\n",
       "        value: 0.9192365407943726\n",
       "        value: -0.20413534343242645\n",
       "        value: -0.992947518825531\n",
       "        value: 0.9228846430778503\n",
       "        value: -0.17974382638931274\n",
       "        value: 0.8134272694587708\n",
       "        value: 0.3081131875514984\n",
       "        value: 0.9814066886901855\n",
       "        value: -0.30775192379951477\n",
       "        value: -0.9979097843170166\n",
       "        value: 0.26039597392082214\n",
       "        value: 0.1154254600405693\n",
       "        value: -0.9850113391876221\n",
       "        value: -0.14762039482593536\n",
       "        value: 0.0460919626057148\n",
       "        value: -0.7193474769592285\n",
       "        value: 0.035624995827674866\n",
       "        value: 0.4605472981929779\n",
       "        value: -0.20232869684696198\n",
       "        value: -0.9358704090118408\n",
       "        value: -0.9999460577964783\n",
       "        value: 0.9964762330055237\n",
       "        value: -0.5412636399269104\n",
       "        value: 0.9959030151367188\n",
       "        value: -0.34711748361587524\n",
       "        value: -0.8467785120010376\n",
       "        value: 0.9646186828613281\n",
       "        value: -0.2704584300518036\n",
       "        value: 0.9891543984413147\n",
       "        value: -0.02434861660003662\n",
       "        value: 0.9931716918945312\n",
       "        value: 0.8267183303833008\n",
       "        value: 0.7908993363380432\n",
       "        value: -0.9328992366790771\n",
       "        value: -0.9747946262359619\n",
       "        value: -0.9167671799659729\n",
       "        value: -0.9841775298118591\n",
       "        value: -0.9686797261238098\n",
       "        value: 0.5471988916397095\n",
       "        value: -0.9726107716560364\n",
       "        value: -0.8856027722358704\n",
       "        value: -0.9940360188484192\n",
       "        value: 0.7751184105873108\n",
       "        value: -0.9787068367004395\n",
       "        value: -0.6042654514312744\n",
       "        value: -0.7438167929649353\n",
       "        value: 0.9935137033462524\n",
       "        value: 0.9635453224182129\n",
       "        value: 0.9352119565010071\n",
       "        value: -0.003818969940766692\n",
       "        value: 0.9820680618286133\n",
       "        value: -0.9887178540229797\n",
       "        value: 0.3365743160247803\n",
       "        value: 0.9267038106918335\n",
       "        value: 0.6516968607902527\n",
       "        value: 0.1206754595041275\n",
       "        value: -0.22844861447811127\n",
       "        value: 0.20706656575202942\n",
       "        value: -0.9995871186256409\n",
       "        value: -0.8881445527076721\n",
       "        value: 0.9469501376152039\n",
       "        value: -0.9658234119415283\n",
       "        value: 0.4649026095867157\n",
       "        value: 0.974065363407135\n",
       "        value: 0.9860605597496033\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"id\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"0\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e56ffa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "��Ŀ¼���ļ� .\\imdb �Ѿ����ڡ�\n"
     ]
    }
   ],
   "source": [
    "!mkdir .\\imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5FapV4KEK3CA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FapV4KEK3CA",
    "outputId": "12407a33-fb52-4c1c-c44d-2901ded47464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate full BERT embeddings\n",
    "\n",
    "bertEmbeddingsPath = './imdb/bertEmeddings.tfr'\n",
    "bertEmbeddings.createBertEmbedding(pp_train_data, bertEmbeddingsPath, 0, reverseWordIndex, encoder, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc08adb2-aea9-45a4-939f-58d04621ab05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc08adb2-aea9-45a4-939f-58d04621ab05",
    "outputId": "0b5de314-d7cc-4f58-8464-e9a10bc8ec9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l {bertEmbeddingsPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f42663-75fa-45f8-a0c2-9954ab729e9b",
   "metadata": {
    "id": "e2f42663-75fa-45f8-a0c2-9954ab729e9b"
   },
   "source": [
    "## Constructing the BERT Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e086c35-9654-482f-8efe-eb87304041c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e086c35-9654-482f-8efe-eb87304041c9",
    "outputId": "8f47453f-00f0-40dc-88f5-c65c7fc04b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d54e0c3-c45a-42d1-aa6b-fbe2f6481ebc",
   "metadata": {
    "id": "9d54e0c3-c45a-42d1-aa6b-fbe2f6481ebc"
   },
   "outputs": [],
   "source": [
    "bertGraphPath = './imdb/bert_graph_99.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd9154d7-a856-41fb-9857-4bb8cb7fc785",
   "metadata": {
    "id": "bd9154d7-a856-41fb-9857-4bb8cb7fc785"
   },
   "outputs": [],
   "source": [
    "graph_builder_config = nsl.configs.GraphBuilderConfig(\n",
    "    similarity_threshold=0.99,\n",
    "    lsh_splits=32,\n",
    "    lsh_rounds=15,\n",
    "    random_seed=12345)\n",
    "\n",
    "nsl.tools.build_graph_from_config([bertEmbeddingsPath],\n",
    "                                  bertGraphPath,\n",
    "                                  graph_builder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc6f60da-4773-401f-a1c1-bde1805c3ae1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc6f60da-4773-401f-a1c1-bde1805c3ae1",
    "outputId": "31ff63e0-1d3a-4a01-d747-11fc8bafaab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l {bertGraphPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6cbd5-c59f-4237-ac47-ecd75de219fe",
   "metadata": {
    "id": "b3a6cbd5-c59f-4237-ac47-ecd75de219fe"
   },
   "source": [
    "## Sample Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ad3fae3-7ff2-43a5-b294-eb2783e82d13",
   "metadata": {
    "id": "4ad3fae3-7ff2-43a5-b294-eb2783e82d13"
   },
   "outputs": [],
   "source": [
    "trainDataPath = './imdb/train_data.tfr'\n",
    "testDataPath = './imdb/test_data.tfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e5ee589-3ee1-4c59-bf3a-37bd85b792d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e5ee589-3ee1-4c59-bf3a-37bd85b792d5",
    "outputId": "ad1eef77-fdc2-4778-9e94-830c166de826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_record_id = train.createRecords(pp_train_data,\n",
    "                                pp_train_labels,\n",
    "                                trainDataPath,\n",
    "                                0)\n",
    "train.createRecords(pp_test_data,\n",
    "               pp_test_labels,\n",
    "               testDataPath,\n",
    "               next_record_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8e810-1537-4c90-80ff-eb8812c46588",
   "metadata": {
    "id": "36e8e810-1537-4c90-80ff-eb8812c46588"
   },
   "source": [
    "## Augment the training data using graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f416d976-8a70-4c4d-a04f-598d74a545bb",
   "metadata": {
    "id": "f416d976-8a70-4c4d-a04f-598d74a545bb"
   },
   "outputs": [],
   "source": [
    "nslTrainPath = './imdb/nsl_train_data.tfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c2dc1df0-3900-407e-8449-0611faed6f91",
   "metadata": {
    "id": "c2dc1df0-3900-407e-8449-0611faed6f91"
   },
   "outputs": [],
   "source": [
    "nsl.tools.pack_nbrs(\n",
    "    trainDataPath,\n",
    "    '',\n",
    "    bertGraphPath,\n",
    "    nslTrainPath,\n",
    "    add_undirected_edges=True,\n",
    "    max_nbrs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4379fd05-7b25-4ae8-afe1-08f5a983eb7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4379fd05-7b25-4ae8-afe1-08f5a983eb7f",
    "outputId": "52dd7bc2-9592-4256-aa74-132feb54e2b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l {nslTrainPath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "62f08399-b72d-4ee0-8cc8-aa16c2a609b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62f08399-b72d-4ee0-8cc8-aa16c2a609b4",
    "outputId": "6a4c0065-f568-4c66-c76c-7e68f64f44cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l {trainDataPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbabe7b-8263-4aa6-99e5-c5c8093c07dc",
   "metadata": {
    "id": "cdbabe7b-8263-4aa6-99e5-c5c8093c07dc"
   },
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af990c-967c-4bd9-bcab-7c6d7e313fa1",
   "metadata": {
    "id": "98af990c-967c-4bd9-bcab-7c6d7e313fa1"
   },
   "source": [
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0G8QR80QOy_S",
   "metadata": {
    "id": "0G8QR80QOy_S"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "NBR_WEIGHT_SUFFIX = '_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95805538-265a-4a1e-8e69-d5fbf326cbb1",
   "metadata": {
    "id": "95805538-265a-4a1e-8e69-d5fbf326cbb1"
   },
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    \"\"\"\n",
    "    Hyperparameters used for training.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # dataset parameters\n",
    "        self.num_classes = 2\n",
    "        self.max_seq_length = 256\n",
    "        self.vocab_size = 10000\n",
    "        # neural graph learning parameters\n",
    "        self.distance_type = nsl.configs.DistanceType.L2\n",
    "        self.graph_regularization_multiplier = 0.1\n",
    "        self.num_neighbors = 2\n",
    "        # model architecture\n",
    "        self.num_embedding_dims = 16\n",
    "        self.num_lstm_dims = 64\n",
    "        self.num_fc_units = 64\n",
    "        # training parameters\n",
    "        self.train_epochs = 20\n",
    "        self.batch_size = 128\n",
    "        # eval parameters\n",
    "        self.eval_steps = None  # All instances in the test set are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7fe23718-d03e-47bc-9451-11d8fdfcd212",
   "metadata": {
    "id": "7fe23718-d03e-47bc-9451-11d8fdfcd212"
   },
   "outputs": [],
   "source": [
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65_BUyTOThzE",
   "metadata": {
    "id": "65_BUyTOThzE",
    "tags": []
   },
   "source": [
    "### Build Traininig and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "vqigJ7EnOpsL",
   "metadata": {
    "id": "vqigJ7EnOpsL"
   },
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "train_dataset = train.makeDataset(trainDataPath, HPARAMS, NBR_FEATURE_PREFIX, NBR_WEIGHT_SUFFIX, True)\n",
    "test_dataset = train.makeDataset(testDataPath, HPARAMS, NBR_FEATURE_PREFIX, NBR_WEIGHT_SUFFIX, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0bnGBGLURhU",
   "metadata": {
    "id": "s0bnGBGLURhU"
   },
   "source": [
    "### Build Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "LzzGvGQuUV77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzzGvGQuUV77",
    "outputId": "2d75d335-cd59-46d5-c88b-fac3ce64a702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "validation_fraction = 0.5\n",
    "validation_size = int(validation_fraction *\n",
    "                      int(training_samples_count / HPARAMS.batch_size))\n",
    "print(validation_size)\n",
    "validation_dataset = train_dataset.take(validation_size)\n",
    "train_dataset = train_dataset.skip(validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48770a57-8748-41b8-86b8-95cb7035ba49",
   "metadata": {
    "id": "48770a57-8748-41b8-86b8-95cb7035ba49"
   },
   "source": [
    "## Setting up Base Models (Bi-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daaa227-cbe1-470f-9f71-7243fd8b0c07",
   "metadata": {
    "id": "7daaa227-cbe1-470f-9f71-7243fd8b0c07"
   },
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "_uwHmlJRVoJ5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uwHmlJRVoJ5",
    "outputId": "b15ac51d-46a1-44d9-8105-45fe7f9895e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words (InputLayer)          [(None, 256)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 256, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              41472     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,793\n",
      "Trainable params: 209,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build Bi-LSTM model\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.makeBilstmModel(HPARAMS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "lNjp9UQrV060",
   "metadata": {
    "id": "lNjp9UQrV060"
   },
   "outputs": [],
   "source": [
    "# set loss function and optimizer\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3126a2-34b0-4263-879e-7e05f2233865",
   "metadata": {
    "id": "be3126a2-34b0-4263-879e-7e05f2233865"
   },
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "nJheMkn5V6yr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJheMkn5V6yr",
    "outputId": "3ddfc3e2-1f01-4744-ba96-ce6cc0fd83b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\functional.py:559: UserWarning: Input dict contained keys ['NL_nbr_0_words', 'NL_nbr_1_words', 'NL_nbr_0_weight', 'NL_nbr_1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 11s 80ms/step - loss: 0.6532 - accuracy: 0.5703 - val_loss: 0.5549 - val_accuracy: 0.7775\n",
      "Epoch 2/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.4414 - accuracy: 0.8031 - val_loss: 0.4166 - val_accuracy: 0.8297\n",
      "Epoch 3/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.3334 - accuracy: 0.8646 - val_loss: 0.2994 - val_accuracy: 0.8619\n",
      "Epoch 4/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.3031 - accuracy: 0.8761 - val_loss: 0.3033 - val_accuracy: 0.8997\n",
      "Epoch 5/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.2687 - accuracy: 0.8949 - val_loss: 0.2620 - val_accuracy: 0.9017\n",
      "Epoch 6/20\n",
      "99/99 [==============================] - 8s 74ms/step - loss: 0.2483 - accuracy: 0.9099 - val_loss: 0.2645 - val_accuracy: 0.8847\n",
      "Epoch 7/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.2265 - accuracy: 0.9156 - val_loss: 0.3493 - val_accuracy: 0.8990\n",
      "Epoch 8/20\n",
      "99/99 [==============================] - 8s 76ms/step - loss: 0.2217 - accuracy: 0.9185 - val_loss: 0.2494 - val_accuracy: 0.8942\n",
      "Epoch 9/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.2061 - accuracy: 0.9229 - val_loss: 0.2324 - val_accuracy: 0.9224\n",
      "Epoch 10/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.1950 - accuracy: 0.9265 - val_loss: 0.1997 - val_accuracy: 0.9207\n",
      "Epoch 11/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.1898 - accuracy: 0.9308 - val_loss: 0.2637 - val_accuracy: 0.8701\n",
      "Epoch 12/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.1723 - accuracy: 0.9387 - val_loss: 0.2017 - val_accuracy: 0.9264\n",
      "Epoch 13/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.1715 - accuracy: 0.9391 - val_loss: 0.2025 - val_accuracy: 0.9139\n",
      "Epoch 14/20\n",
      "99/99 [==============================] - 8s 74ms/step - loss: 0.1645 - accuracy: 0.9409 - val_loss: 0.1824 - val_accuracy: 0.9367\n",
      "Epoch 15/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.1450 - accuracy: 0.9501 - val_loss: 0.3262 - val_accuracy: 0.8752\n",
      "Epoch 16/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.1460 - accuracy: 0.9487 - val_loss: 0.2705 - val_accuracy: 0.8784\n",
      "Epoch 17/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.1435 - accuracy: 0.9499 - val_loss: 0.1910 - val_accuracy: 0.9384\n",
      "Epoch 18/20\n",
      "99/99 [==============================] - 7s 74ms/step - loss: 0.1359 - accuracy: 0.9530 - val_loss: 0.1985 - val_accuracy: 0.9389\n",
      "Epoch 19/20\n",
      "99/99 [==============================] - 8s 75ms/step - loss: 0.1374 - accuracy: 0.9526 - val_loss: 0.1577 - val_accuracy: 0.9494\n",
      "Epoch 20/20\n",
      "99/99 [==============================] - 8s 74ms/step - loss: 0.1292 - accuracy: 0.9568 - val_loss: 0.1726 - val_accuracy: 0.9315\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=HPARAMS.train_epochs,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56699b-7473-4297-aa56-8b820d1f09aa",
   "metadata": {
    "id": "0f56699b-7473-4297-aa56-8b820d1f09aa"
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f0vMq3iuWA1L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0vMq3iuWA1L",
    "outputId": "4d6a9800-320b-486f-9694-e4e32f485fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 5s 21ms/step - loss: 0.4932 - accuracy: 0.8266\n",
      "[0.4932301640510559, 0.8265600204467773]\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance on test data\n",
    "results = model.evaluate(test_dataset, steps=HPARAMS.eval_steps)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8bc72-e988-485a-820a-7b7f97c98fbb",
   "metadata": {
    "id": "85b8bc72-e988-485a-820a-7b7f97c98fbb"
   },
   "source": [
    "### Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2cca2741-5009-4191-a6e1-b0b8d5267232",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "2cca2741-5009-4191-a6e1-b0b8d5267232",
    "outputId": "bfcebed6-fff5-49fd-d21b-61a4a7ed9b65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validaiton loss over epochs\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"-r^\" is for solid red line with triangle markers.\n",
    "plt.plot(epochs, loss, '-r^', label='Training loss')\n",
    "# \"-b0\" is for solid blue line with circle markers.\n",
    "plt.plot(epochs, val_loss, '-bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0c446d9-9979-4e59-b8fd-97ec51dac593",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "b0c446d9-9979-4e59-b8fd-97ec51dac593",
    "outputId": "aa47c4f1-765d-4e1f-9e4c-587ec4c3703c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy over epochs\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, '-r^', label='Training acc')\n",
    "plt.plot(epochs, val_acc, '-bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba369a2-7dfc-462a-a769-8a5d1bc73a4f",
   "metadata": {
    "id": "6ba369a2-7dfc-462a-a769-8a5d1bc73a4f"
   },
   "source": [
    "## Graph Regularized BiLSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c66ce-9190-46e7-95f9-15d2a227050a",
   "metadata": {
    "id": "6f5c66ce-9190-46e7-95f9-15d2a227050a"
   },
   "source": [
    "### Switch to the NSL augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "s6VecyEedNSf",
   "metadata": {
    "id": "s6VecyEedNSf"
   },
   "outputs": [],
   "source": [
    "train_dataset = train.makeDataset(nslTrainPath, HPARAMS, NBR_FEATURE_PREFIX, NBR_WEIGHT_SUFFIX, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0968c-139e-49ef-ba57-0c9f0c979f72",
   "metadata": {
    "id": "1ed0968c-139e-49ef-ba57-0c9f0c979f72"
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a6c3222-743e-4fd2-a106-68f2bbdd939b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a6c3222-743e-4fd2-a106-68f2bbdd939b",
    "outputId": "d7a756e8-2133-45fd-d452-2e2534306311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words (InputLayer)          [(None, 256)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 256, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              41472     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,793\n",
      "Trainable params: 209,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a new LSTM model for graph regularization\n",
    "tf.keras.backend.clear_session()\n",
    "modelBase = models.makeBilstmModel(HPARAMS)\n",
    "modelBase.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ddf29b59-296b-4330-b57f-9f7e058c5756",
   "metadata": {
    "id": "ddf29b59-296b-4330-b57f-9f7e058c5756"
   },
   "outputs": [],
   "source": [
    "# Wrap the base model with graph regularization\n",
    "graphRegConfig = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=HPARAMS.num_neighbors,\n",
    "    multiplier=HPARAMS.graph_regularization_multiplier,\n",
    "    distance_type=HPARAMS.distance_type,\n",
    "    sum_over_axis=-1)\n",
    "\n",
    "graphRegModel = nsl.keras.GraphRegularization(modelBase,\n",
    "                                              graphRegConfig)\n",
    "graphRegModel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PTwv5bLugt41",
   "metadata": {
    "id": "PTwv5bLugt41"
   },
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a52ad69-176a-4fbf-adb6-576880f00f8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a52ad69-176a-4fbf-adb6-576880f00f8a",
    "outputId": "0127275d-3d1d-4ea3-986e-dd9aa06d0a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 28s 119ms/step - loss: 0.6192 - accuracy: 0.6557 - scaled_graph_loss: 0.0388 - val_loss: 0.4576 - val_accuracy: 0.7819\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.5303 - accuracy: 0.8208 - scaled_graph_loss: 0.0806 - val_loss: 0.4398 - val_accuracy: 0.8667\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.4993 - accuracy: 0.8406 - scaled_graph_loss: 0.0852 - val_loss: 0.4161 - val_accuracy: 0.8336\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 23s 119ms/step - loss: 0.4739 - accuracy: 0.8438 - scaled_graph_loss: 0.0852 - val_loss: 0.3513 - val_accuracy: 0.8648\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.4554 - accuracy: 0.8431 - scaled_graph_loss: 0.0817 - val_loss: 0.3195 - val_accuracy: 0.8767\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.4307 - accuracy: 0.8496 - scaled_graph_loss: 0.0814 - val_loss: 0.3701 - val_accuracy: 0.8160\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 23s 117ms/step - loss: 0.4170 - accuracy: 0.8531 - scaled_graph_loss: 0.0791 - val_loss: 0.3377 - val_accuracy: 0.8361\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.3997 - accuracy: 0.8571 - scaled_graph_loss: 0.0784 - val_loss: 0.3222 - val_accuracy: 0.8265\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3832 - accuracy: 0.8608 - scaled_graph_loss: 0.0759 - val_loss: 0.3141 - val_accuracy: 0.8474\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3863 - accuracy: 0.8556 - scaled_graph_loss: 0.0751 - val_loss: 0.2884 - val_accuracy: 0.8533\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.3720 - accuracy: 0.8626 - scaled_graph_loss: 0.0733 - val_loss: 0.2573 - val_accuracy: 0.9156\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.3667 - accuracy: 0.8640 - scaled_graph_loss: 0.0727 - val_loss: 0.2901 - val_accuracy: 0.8549\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.3475 - accuracy: 0.8704 - scaled_graph_loss: 0.0709 - val_loss: 0.2958 - val_accuracy: 0.8715\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3397 - accuracy: 0.8706 - scaled_graph_loss: 0.0692 - val_loss: 0.2635 - val_accuracy: 0.8558\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3323 - accuracy: 0.8751 - scaled_graph_loss: 0.0692 - val_loss: 0.2663 - val_accuracy: 0.8657\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 23s 117ms/step - loss: 0.3243 - accuracy: 0.8761 - scaled_graph_loss: 0.0668 - val_loss: 0.2522 - val_accuracy: 0.8809\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.3143 - accuracy: 0.8768 - scaled_graph_loss: 0.0656 - val_loss: 0.2341 - val_accuracy: 0.8578\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3089 - accuracy: 0.8820 - scaled_graph_loss: 0.0651 - val_loss: 0.2468 - val_accuracy: 0.8680\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3155 - accuracy: 0.8788 - scaled_graph_loss: 0.0650 - val_loss: 0.2214 - val_accuracy: 0.8964\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 0.3107 - accuracy: 0.8771 - scaled_graph_loss: 0.0639 - val_loss: 0.2372 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "graph_reg_history = graphRegModel.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=HPARAMS.train_epochs,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KLzcTAaAg3Sq",
   "metadata": {
    "id": "KLzcTAaAg3Sq"
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "HISaCAJhg77a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HISaCAJhg77a",
    "outputId": "7c093603-bf10-4bca-ea64-fc7354c22f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 6s 22ms/step - loss: 0.5676 - accuracy: 0.7524\n",
      "[0.5676329135894775, 0.7523999810218811]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance on test set\n",
    "graph_reg_results = graphRegModel.evaluate(test_dataset, steps=HPARAMS.eval_steps)\n",
    "print(graph_reg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6wI1sinpg4u2",
   "metadata": {
    "id": "6wI1sinpg4u2"
   },
   "source": [
    "### Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "k7kVVvhUhu6C",
   "metadata": {
    "id": "k7kVVvhUhu6C"
   },
   "outputs": [],
   "source": [
    "# five entries in total in the dictionary: \n",
    "# training loss, training accuracy, training graph loss, \n",
    "# validation loss, and validation accuracy\n",
    "graph_reg_history_dict = graph_reg_history.history\n",
    "# graph_reg_history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "rI6lXCZXiRo9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rI6lXCZXiRo9",
    "outputId": "886aaf03-b35f-45e6-e4b1-c6e8623c2790"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "acc = graph_reg_history_dict['accuracy']\n",
    "val_acc = graph_reg_history_dict['val_accuracy']\n",
    "loss = graph_reg_history_dict['loss']\n",
    "graph_loss = graph_reg_history_dict['scaled_graph_loss']\n",
    "val_loss = graph_reg_history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "# \"-r^\" is for solid red line with triangle markers.\n",
    "plt.plot(epochs, loss, '-r^', label='Training loss')\n",
    "# \"-gD\" is for solid green line with diamond markers.\n",
    "plt.plot(epochs, graph_loss, '-gD', label='Training graph loss')\n",
    "# \"-b0\" is for solid blue line with circle markers.\n",
    "plt.plot(epochs, val_loss, '-bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "nLc5zSDkiVyk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "nLc5zSDkiVyk",
    "outputId": "f2325205-3197-4703-a4fc-29795aa6cd22"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, '-r^', label='Training acc')\n",
    "plt.plot(epochs, val_acc, '-bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xHTR-C29g6tS",
   "metadata": {
    "id": "xHTR-C29g6tS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b7e1cb4-9f77-4a43-8162-24cc7cd0808a",
   "metadata": {
    "id": "3b7e1cb4-9f77-4a43-8162-24cc7cd0808a"
   },
   "source": [
    "## CNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dbe34-05f0-4a8a-b4e8-e4efd504986a",
   "metadata": {
    "id": "869dbe34-05f0-4a8a-b4e8-e4efd504986a"
   },
   "source": [
    "### Same categories as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2756196-6278-4d93-b820-0af455624d48",
   "metadata": {
    "id": "a2756196-6278-4d93-b820-0af455624d48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a5809-b610-47bf-8531-0bc71731bfdf",
   "metadata": {
    "id": "0f8a5809-b610-47bf-8531-0bc71731bfdf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e477ea7-40c6-415c-ab64-99b7cbe6f751",
   "metadata": {
    "id": "9e477ea7-40c6-415c-ab64-99b7cbe6f751"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777323d4",
   "metadata": {},
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fd299",
   "metadata": {
    "id": "DVSgz9Ml08u3"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b35b14",
   "metadata": {
    "id": "DD83JJCD1N8Z"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# dataset = Citation(data, normalize_x=True, transforms=[LayerPreprocess(GCNConv)])\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(pp_train_data, pp_train_labels), (pp_test_data, pp_test_labels) = (\n",
    "    imdb.load_data(num_words=10000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e9fcf8",
   "metadata": {
    "id": "eGI7DEOxIlQM"
   },
   "outputs": [],
   "source": [
    "# This block limits how much is loaded to keep debugging short\n",
    "# don't run on the final experiments\n",
    "validation_fraction = 0.5\n",
    "limit = 5000\n",
    "\n",
    "pp_validation_data = pp_train_data[0: int(limit * validation_fraction)]\n",
    "pp_validation_labels = pp_train_labels[0: int(limit * validation_fraction)]\n",
    "pp_train_data = pp_train_data[int(limit * validation_fraction): limit]\n",
    "pp_train_labels = pp_train_labels[int(limit * validation_fraction): limit]\n",
    "pp_test_data = pp_test_data[0:limit]\n",
    "pp_test_labels = pp_test_labels[0:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baad270c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqKhzLNj1xQB",
    "outputId": "5c7b9890-d233-4e49-d09e-8fb37185645a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 2500, labels: 2500\n"
     ]
    }
   ],
   "source": [
    "print('Training entries: {}, labels: {}'.format(\n",
    "    len(pp_train_data), len(pp_train_labels)))\n",
    "training_samples_count = len(pp_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77334eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 2500, labels: 2500\n"
     ]
    }
   ],
   "source": [
    "print('Training entries: {}, labels: {}'.format(\n",
    "    len(pp_validation_data), len(pp_validation_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c7fc819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBZF3Dy5115r",
    "outputId": "7b9ceb22-0776-4c9a-91c3-d2e2fb0e02b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 69, 115, 557, 7, 14, 509, 466, 4, 2025, 8, 742, 7502, 625, 1169, 1055, 5, 29, 739, 11, 6, 55, 163, 696, 227, 5, 27, 2, 1502, 167, 2156, 6504, 433, 75, 1637, 14, 56, 11, 6, 2, 3979, 18, 470, 3816, 2280, 2512, 33, 15, 51, 6, 1758, 5, 2211, 866, 21, 95, 146, 7, 4, 652, 15, 48, 1024, 2023, 4732, 9, 11, 12, 25, 191, 30, 685, 14, 16, 55, 2781, 7, 148, 8002, 1290, 39, 1831, 11, 4, 3065, 608, 19, 53, 5401, 14, 9, 35, 9694, 5, 33, 211, 5565, 2, 163, 22, 4, 779, 5436, 93, 72, 462, 38, 254, 13, 16, 2578, 382, 4, 1529, 361, 7, 2, 11, 20, 479, 279, 12, 16, 4, 364, 1398, 13, 69, 170, 11, 21, 13, 296, 19, 6, 604, 7, 84, 5, 75, 69, 6, 5154, 118, 457, 207, 1084, 11, 2088]\n"
     ]
    }
   ],
   "source": [
    "print(pp_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8afb514d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmvSSg9O13tE",
    "outputId": "40337244-b075-483a-ab62-5a065b920a20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 139)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_train_data[0]), len(pp_train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99a460a",
   "metadata": {
    "id": "YbLPfq6y15wT"
   },
   "outputs": [],
   "source": [
    "def sampleFunction(inputFeature):\n",
    "    \"\"\"\n",
    "    This is a description of the function\n",
    "    \n",
    "    Args:\n",
    "        inputFeature - (np.ndarray) This is what the feature is\n",
    "    Returns:\n",
    "        result - (int) This is what is returned\n",
    "    \"\"\"\n",
    "\n",
    "    result = 55\n",
    "    return result\n",
    "\n",
    "def buildReverseWordIndex(dataset):\n",
    "    \"\"\"\n",
    "    Convert the index back to words with proper accounting for \n",
    "    the special characters reserved at the beginning of the dictionary\n",
    "\n",
    "    Args: \n",
    "        dataset - (keras.dataset) The dataset to use\n",
    "    Returns:\n",
    "        buildReverseWordIndex - (dict) A dictionary mapping words to an integer index\n",
    "    \"\"\"\n",
    "    wordIndex = dataset.get_word_index()\n",
    "\n",
    "    # The first indices are reserved\n",
    "    wordIndex = {k: (v + 3) for k, v in wordIndex.items()}\n",
    "    wordIndex['<PAD>'] = 0\n",
    "    wordIndex['<START>'] = 1\n",
    "    wordIndex['<UNK>'] = 2  # unknown\n",
    "    wordIndex['<UNUSED>'] = 3\n",
    "    return dict((value, key) for (key, value) in wordIndex.items())\n",
    "\n",
    "def decodeReview(text, reverseWordIndex):\n",
    "    \"\"\"\n",
    "    Uses build_reverse_word_index to decode original data format into text\n",
    "    \n",
    "    Args:\n",
    "        text - (np.ndarray) The text to decode\n",
    "        reverseWordIndex - (dict) The reverse word index to use\n",
    "    Returns:\n",
    "        decodedReview - (string) The decoded review\n",
    "    \"\"\"\n",
    "    return ' '.join([reverseWordIndex.get(i, '?') for i in text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1884c3a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "SPdl56b8Ra_J",
    "outputId": "8a943c17-c393-4104-c9d7-aa186773dc05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> i had never heard of this flick despite the connection to george clooney whose company produced and he appears in a very funny supporting bit and his <UNK> 11 director steven soderbergh worse we picked this up in a <UNK> bin for 4 99 canadian dollars at that what a grand and pleasant surprise but then i'm of the opinion that if william h macy is in it you can't be disappointed this was very reminiscent of those ealing comedies from england in the 1950s ok with more profanity this is an oddball and at times gut <UNK> funny film the actual heist made me laugh so hard i was crying perhaps the funniest use of <UNK> in movie history maybe it was the low expectations i had going in but i watched with a group of people and we had a blast best 5 i've spent in ages\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverseWordIndex = buildReverseWordIndex(imdb)\n",
    "decodeReview(pp_train_data[0], reverseWordIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223e000",
   "metadata": {
    "id": "PQpLmTebRnAZ"
   },
   "source": [
    "### Generate BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73edd71d",
   "metadata": {
    "id": "cTnGjdmhB3Dm"
   },
   "outputs": [],
   "source": [
    "pretrained_embedding = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722cb125",
   "metadata": {
    "id": "1CfB4xjXI2CH"
   },
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866efae2",
   "metadata": {
    "id": "Ct_h4nM-Mmx2"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = preprocessor(text_input)\n",
    "\n",
    "encoder = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2',\n",
    "    trainable=True)\n",
    "\n",
    "outputs = encoder(encoder_inputs)\n",
    "\n",
    "pooled_output = outputs['pooled_output'] # [batch_size, 128].\n",
    "# [batch_size, seq_length, 128].\n",
    "\n",
    "sequence_output = outputs['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82af6486",
   "metadata": {
    "id": "Ufh8vif4P8PH"
   },
   "outputs": [],
   "source": [
    "def int64Feature(value):\n",
    "    \"\"\"\n",
    "    Returns int64 tf.train.Feature.\n",
    "\n",
    "    Args:\n",
    "        value - (np.ndarray) array of ints\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value.tolist()))\n",
    "\n",
    "\n",
    "def bytesFeature(value):\n",
    "    \"\"\"\n",
    "    Returns bytes tf.train.Feature.\n",
    "\n",
    "    Args:\n",
    "        value - (string) string\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[value.encode('utf-8')]))\n",
    "\n",
    "\n",
    "def floatFeature(value):\n",
    "    \"\"\"\n",
    "    Returns float tf.train.Feature.\n",
    "\n",
    "    Args:\n",
    "        value - (np.ndarray) array of floats\n",
    "\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "000667cc",
   "metadata": {
    "id": "5uYvmHZRJA8y"
   },
   "outputs": [],
   "source": [
    "def createBertEmbeddingExample(wordVector, recordID, reverseWordIndex, encoder, preprocessor):\n",
    "    \"\"\"\n",
    "    Create tf.Example containing the sample's embedding and its ID.\n",
    "    \n",
    "    Args:\n",
    "        wordVector - (np.ndarray) the text to decode\n",
    "        recordId - (int) ID of the sample\n",
    "        reverseWordIndex - (dict) The reverse word index to use\n",
    "        encoder - (string) encoder name\n",
    "        preprocessor - (string) preprocessor name\n",
    "    Returns:\n",
    "        example - (tf.Example) tf.Example containing the sample's embedding and its ID\n",
    "    \"\"\"\n",
    "\n",
    "    text = decodeReview(wordVector, reverseWordIndex)\n",
    "\n",
    "    # Shape = [batch_size,].\n",
    "    sentenceEmbedding = encoder(preprocessor(tf.reshape(text, shape=[-1, ])))['pooled_output']\n",
    "    \n",
    "    # Flatten the sentence embedding back to 1-D.\n",
    "    sentenceEmbedding = tf.reshape(sentenceEmbedding, shape=[-1])\n",
    "    \n",
    "    features = {\n",
    "        'id': bytesFeature(str(recordID)),\n",
    "        'embedding': floatFeature(sentenceEmbedding.numpy())\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "\n",
    "def createBertEmbedding(wordVectors, outputPath, startingRecordId, reverseWordIndex, encoder, preprocessor):\n",
    "    \"\"\"\n",
    "    Create full set of BERT embeddings\n",
    "\n",
    "    Args:\n",
    "        wordVectors - (np.ndarray) all text to decode\n",
    "        outputPath - (string) path to output file\n",
    "        startingRecordId - (int) ID of the first sample\n",
    "        reverseWordIndex - (dict) The reverse word index to use\n",
    "        encoder - (string) encoder name\n",
    "        preprocessor - (string) preprocessor name\n",
    "    Returns:\n",
    "        recordID - (int) ID of the last sample\n",
    "    \"\"\"\n",
    "    recordID = int(startingRecordId)\n",
    "    with tf.io.TFRecordWriter(outputPath) as writer:\n",
    "        for word_vector in wordVectors:\n",
    "            example = createBertEmbeddingExample(word_vector, recordID, reverseWordIndex, encoder, preprocessor)\n",
    "            recordID = recordID + 1\n",
    "            writer.write(example.SerializeToString())\n",
    "    return recordID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b17e56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTmKLj4gRLSv",
    "outputId": "7a70f572-154c-4b18-ad82-1a9268bc8489"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�����﷨����ȷ��\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6ed47e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXb_OhcmJDEO",
    "outputId": "016ce2ba-5ee5-45b2-e9dd-c5a52e50bd47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./imdb/bertEmeddings.tfr'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate full BERT embeddings\n",
    "\n",
    "bertEmbeddingsPath = './imdb/bertEmeddings.tfr'\n",
    "createBertEmbedding(pp_train_data, bertEmbeddingsPath, 0, reverseWordIndex, encoder, preprocessor)\n",
    "\n",
    "bertEmbeddingsPath_validation = './imdb/bertEmeddings_validation.tfr'\n",
    "createBertEmbedding(pp_validation_data, bertEmbeddingsPath_validation, 0, reverseWordIndex, encoder, preprocessor)\n",
    "\n",
    "bertEmbeddingsPath_test = './imdb/bertEmeddings_test.tfr'\n",
    "createBertEmbedding(pp_test_data, bertEmbeddingsPath_test, 0, reverseWordIndex, encoder, preprocessor)\n",
    "bertEmbeddingsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a7d605",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJRw0CsFJJUw",
    "outputId": "bca54480-a723-455a-dee1-e11710875503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./imdb/bertEmeddings.tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1dc192",
   "metadata": {
    "id": "GVGFh9lpSCL4"
   },
   "outputs": [],
   "source": [
    "def createBertEmbeddingExample_tf(wordVector, reverseWordIndex, encoder, preprocessor):\n",
    "    \"\"\"\n",
    "    Create tf.Example containing the sample's embedding and its ID.\n",
    "    \n",
    "    Args:\n",
    "        wordVector - (np.ndarray) the text to decode\n",
    "        recordId - (int) ID of the sample\n",
    "        reverseWordIndex - (dict) The reverse word index to use\n",
    "        encoder - (string) encoder name\n",
    "        preprocessor - (string) preprocessor name\n",
    "    Returns:\n",
    "        example - (tf.Example) tf.Example containing the sample's embedding and its ID\n",
    "    \"\"\"\n",
    "\n",
    "    text = decodeReview(wordVector, reverseWordIndex)\n",
    "\n",
    "    # Shape = [batch_size,].\n",
    "    sentenceEmbedding = encoder(preprocessor(tf.reshape(text, shape=[-1, ])))['pooled_output']\n",
    "    \n",
    "    # Flatten the sentence embedding back to 1-D.\n",
    "    sentenceEmbedding = tf.reshape(sentenceEmbedding, shape=[-1])\n",
    "    \n",
    "    # features = {\n",
    "    #     'id': bytesFeature(str(recordID)),\n",
    "    #     'embedding': floatFeature(sentenceEmbedding.numpy())\n",
    "    # }\n",
    "    # return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return sentenceEmbedding\n",
    "\n",
    "def createBertEmbedding_tf(wordVectors, reverseWordIndex, encoder, preprocessor):\n",
    "    \"\"\"\n",
    "    Create full set of BERT embeddings\n",
    "\n",
    "    Args:\n",
    "        wordVectors - (np.ndarray) all text to decode\n",
    "        outputPath - (string) path to output file\n",
    "        startingRecordId - (int) ID of the first sample\n",
    "        reverseWordIndex - (dict) The reverse word index to use\n",
    "        encoder - (string) encoder name\n",
    "        preprocessor - (string) preprocessor name\n",
    "    Returns:\n",
    "        recordID - (int) ID of the last sample\n",
    "    \"\"\"\n",
    "    sentenceEmbeddings = []\n",
    "    for word_vector in wordVectors:\n",
    "        example = createBertEmbeddingExample_tf(word_vector, reverseWordIndex, encoder, preprocessor)\n",
    "        sentenceEmbeddings.append(example)\n",
    "    sentenceEmbeddings_np = np.array(sentenceEmbeddings)\n",
    "    return sentenceEmbeddings_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dac10e0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoZyVpjFVSen",
    "outputId": "b77b203a-9028-45fd-e60e-3817d65f30db"
   },
   "outputs": [],
   "source": [
    "bertEmbeddings_np = createBertEmbedding_tf(pp_train_data, reverseWordIndex, encoder, preprocessor)\n",
    "bertEmbeddings_np\n",
    "\n",
    "bertEmbeddings_va_np = createBertEmbedding_tf(pp_validation_data, reverseWordIndex, encoder, preprocessor)\n",
    "bertEmbeddings_te_np = createBertEmbedding_tf(pp_test_data, reverseWordIndex, encoder, preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79dc973b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWUInMm2Wrpm",
    "outputId": "a8da0080-076f-43a1-845e-68ee98bc5f0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(bertEmbeddings_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc287c",
   "metadata": {
    "id": "LzDo6ZjnUqgH"
   },
   "source": [
    "### Construct Graph Using BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f26461",
   "metadata": {
    "id": "NYlVf9jm3RE7"
   },
   "outputs": [],
   "source": [
    "graph_builder_config = nsl.configs.GraphBuilderConfig(\n",
    "    similarity_threshold=0.99, lsh_splits=32, lsh_rounds=15, random_seed=42)\n",
    "nsl.tools.build_graph_from_config(['./imdb/bertEmeddings.tfr'],\n",
    "                                  './imdb/graph_99.tsv',\n",
    "                                  graph_builder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4eab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder_config = nsl.configs.GraphBuilderConfig(\n",
    "    similarity_threshold=0.99, lsh_splits=32, lsh_rounds=15, random_seed=42)\n",
    "nsl.tools.build_graph_from_config(['./imdb/bertEmeddings_test.tfr'],\n",
    "                                  './imdb/graph_99_test.tsv',\n",
    "                                  graph_builder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15da11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder_config = nsl.configs.GraphBuilderConfig(\n",
    "    similarity_threshold=0.99, lsh_splits=32, lsh_rounds=15, random_seed=42)\n",
    "nsl.tools.build_graph_from_config(['./imdb/bertEmeddings_validation.tfr'],\n",
    "                                  './imdb/graph_99_validation.tsv',\n",
    "                                  graph_builder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cd97b07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVzjbEVb3THo",
    "outputId": "809d902b-33ff-41f1-ca58-29ec358b3339"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./imdb/graph_99.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6a8db",
   "metadata": {
    "id": "qoI9TG43hJOd"
   },
   "source": [
    "### Convert NSL Graph to Spektral Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2cb15b6",
   "metadata": {
    "id": "WU2COjGyf-4h"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./imdb/graph_99.tsv', sep=\"\\t\") \n",
    "imdb_graph_a_adjacency_matrix = df.values\n",
    "size = len(pp_train_data)\n",
    "imdb_graph_a = np.zeros((size, size))\n",
    "for row in imdb_graph_a_adjacency_matrix:\n",
    "  imdb_graph_a[int(row[0]),int(row[1])] = row[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72aea348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./imdb/graph_99_validation.tsv', sep=\"\\t\") \n",
    "imdb_graph_va_a_adjacency_matrix = df.values\n",
    "size = len(pp_validation_data)\n",
    "imdb_graph_va_a = np.zeros((size, size))\n",
    "for row in imdb_graph_va_a_adjacency_matrix:\n",
    "  imdb_graph_va_a[int(row[0]),int(row[1])] = row[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ab8ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./imdb/graph_99_test.tsv', sep=\"\\t\") \n",
    "imdb_graph_te_a_adjacency_matrix = df.values\n",
    "size = len(pp_test_data)\n",
    "imdb_graph_te_a = np.zeros((size, size))\n",
    "for row in imdb_graph_te_a_adjacency_matrix:\n",
    "  imdb_graph_te_a[int(row[0]),int(row[1])] = row[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b31b15f4",
   "metadata": {
    "id": "hWJkIf1f0Yai"
   },
   "outputs": [],
   "source": [
    "max_seq_length_slice = 256\n",
    "# pp_train_data_sliced = np.zeros((len(pp_train_data), max_seq_length_slice))\n",
    "# i = 0\n",
    "# while i < len(pp_train_data):\n",
    "#   if len(pp_train_data[i]) > max_seq_length_slice:\n",
    "#     pp_train_data_sliced[i] = pp_train_data[i][:max_seq_length_slice]\n",
    "#   else:\n",
    "#     pp_train_data_sliced[i] = np.append(np.array(pp_train_data[i]), np.zeros(max_seq_length_slice - len(pp_train_data[i])))\n",
    "#   i = i + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e6a83ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkWbvN8DLQRv",
    "outputId": "6bb1fe97-b001-47f7-8413-9696d6aa8b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 128\n",
      "(2500, 128)\n"
     ]
    }
   ],
   "source": [
    "print(len(bertEmbeddings_np),len(bertEmbeddings_np[0]))\n",
    "print(bertEmbeddings_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11780416",
   "metadata": {
    "id": "771tOMM4-Xqb"
   },
   "outputs": [],
   "source": [
    "pp_train_labels_binary = np.zeros((len(pp_train_labels),2))\n",
    "j = 0\n",
    "for _ in pp_train_labels:\n",
    "  if _ == 1:\n",
    "    pp_train_labels_binary[j][1] = 1\n",
    "  else:\n",
    "    pp_train_labels_binary[j][0] = 1\n",
    "  j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6247f322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d835b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_validation_labels_binary = np.zeros((len(pp_validation_labels),2))\n",
    "j = 0\n",
    "for _ in pp_validation_labels:\n",
    "  if _ == 1:\n",
    "    pp_validation_labels_binary[j][1] = 1\n",
    "  else:\n",
    "    pp_validation_labels_binary[j][0] = 1\n",
    "  j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3983468",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_test_labels_binary = np.zeros((len(pp_test_labels),2))\n",
    "j = 0\n",
    "for _ in pp_test_labels:\n",
    "  if _ == 1:\n",
    "    pp_test_labels_binary[j][1] = 1\n",
    "  else:\n",
    "    pp_test_labels_binary[j][0] = 1\n",
    "  j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7552242",
   "metadata": {
    "id": "yyTkJnFWvrTN"
   },
   "outputs": [],
   "source": [
    "imdb_graph=Graph(a=imdb_graph_a, x=bertEmbeddings_np, y=pp_train_labels_binary)\n",
    "imdb_graph_va=Graph(a=imdb_graph_va_a, x=bertEmbeddings_va_np, y=pp_validation_labels_binary)\n",
    "imdb_graph_te=Graph(a=imdb_graph_te_a, x=bertEmbeddings_te_np, y=pp_test_labels_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75c3d704",
   "metadata": {
    "id": "DPa0n4Hm3aAo"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset of five random graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, graph, **kwargs):\n",
    "        # self.nodes = nodes\n",
    "        # self.feats = feats\n",
    "        self.graph = graph\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def download(self):\n",
    "        # data = ...  # Download from somewhere\n",
    "        path = './imdb'\n",
    "        # Create the directory\n",
    "        \n",
    "        # os.mkdir(path)\n",
    "        # filename = os.path.join(path, 'imdb_graph')\n",
    "        # np.savez(filename, x=imdb_graph.x, a=imdb_graph.a, y=imdb_graph.y)\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        # for i in range(5):\n",
    "        #     data = np.load(os.path.join(self.path, f'graph_{i}.npz'))\n",
    "        #     output.append(\n",
    "        #         Graph(x=data['x'], a=data['a'], y=data['y'])\n",
    "        #     )\n",
    "        output.append(self.graph)\n",
    "        return output           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9f1b9fc",
   "metadata": {
    "id": "MNVYKs-umNGv"
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(imdb_graph)\n",
    "dataset[0]\n",
    "dataset.apply(GCNFilter())\n",
    "\n",
    "dataset_va = MyDataset(imdb_graph_va)\n",
    "dataset_va.apply(GCNFilter())\n",
    "\n",
    "dataset_te = MyDataset(imdb_graph_te)\n",
    "dataset_te.apply(GCNFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "909e32aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waldAe1rtxXy",
    "outputId": "f112bc6f-714b-46dc-fce2-a6c61a704f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x.shape\n",
    "dataset_va[0].x.shape\n",
    "dataset_te[0].x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b97d2a",
   "metadata": {
    "id": "8ryTFVAy1Par"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3360f521",
   "metadata": {
    "id": "OYwt6NlY05QU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "learning_rate = 1e-2\n",
    "seed = 0\n",
    "epochs = 1000\n",
    "patience = 10\n",
    "\n",
    "tf.random.set_seed(seed=seed)  # make weight initialization reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e96291c",
   "metadata": {
    "id": "uz2hIdfTsS3V"
   },
   "outputs": [],
   "source": [
    "model = GCN(n_labels=imdb_graph.n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "465b907d",
   "metadata": {
    "id": "44xDl66O23IP"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=RMSprop(learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    weighted_metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19b0cf8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7T_ZLKIxc2i",
    "outputId": "3b7f7a21-4e8e-4e28-8bce-134e3f18c384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3092 - acc: 0.5044 - val_loss: 1.0295 - val_acc: 0.4872\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1714 - acc: 0.5000 - val_loss: 0.7090 - val_acc: 0.4880\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7492 - acc: 0.5000 - val_loss: 0.6996 - val_acc: 0.4868\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7205 - acc: 0.5052 - val_loss: 0.7003 - val_acc: 0.4872\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7172 - acc: 0.4992 - val_loss: 0.7001 - val_acc: 0.4868\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7140 - acc: 0.5040 - val_loss: 0.7002 - val_acc: 0.4868\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7104 - acc: 0.5080 - val_loss: 0.6997 - val_acc: 0.4876\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7062 - acc: 0.5008 - val_loss: 0.6996 - val_acc: 0.4872\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7062 - acc: 0.5048 - val_loss: 0.6992 - val_acc: 0.4876\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7037 - acc: 0.4996 - val_loss: 0.6987 - val_acc: 0.4872\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7012 - acc: 0.5076 - val_loss: 0.6999 - val_acc: 0.4872\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7007 - acc: 0.5120 - val_loss: 0.6998 - val_acc: 0.4872\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7023 - acc: 0.5040 - val_loss: 0.6993 - val_acc: 0.4872\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7012 - acc: 0.5052 - val_loss: 0.6997 - val_acc: 0.4872\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7018 - acc: 0.5104 - val_loss: 0.6993 - val_acc: 0.4876\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7000 - acc: 0.5112 - val_loss: 0.6983 - val_acc: 0.4872\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7007 - acc: 0.5020 - val_loss: 0.6986 - val_acc: 0.4876\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6999 - acc: 0.5096 - val_loss: 0.6979 - val_acc: 0.4872\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6978 - acc: 0.5104 - val_loss: 0.6981 - val_acc: 0.4868\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6990 - acc: 0.5160 - val_loss: 0.6961 - val_acc: 0.4912\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6997 - acc: 0.5080 - val_loss: 0.6975 - val_acc: 0.4912\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6992 - acc: 0.5124 - val_loss: 0.6972 - val_acc: 0.4980\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6991 - acc: 0.5048 - val_loss: 0.6963 - val_acc: 0.4976\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6995 - acc: 0.5104 - val_loss: 0.6976 - val_acc: 0.5620\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6981 - acc: 0.5260 - val_loss: 0.6954 - val_acc: 0.5828\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6959 - acc: 0.5320 - val_loss: 0.6912 - val_acc: 0.6068\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6945 - acc: 0.5312 - val_loss: 0.6902 - val_acc: 0.5976\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6954 - acc: 0.5192 - val_loss: 0.6933 - val_acc: 0.5268\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6905 - acc: 0.5316 - val_loss: 0.6891 - val_acc: 0.5948\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6947 - acc: 0.5260 - val_loss: 0.6935 - val_acc: 0.5864\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6935 - acc: 0.5324 - val_loss: 0.6893 - val_acc: 0.5692\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6940 - acc: 0.5352 - val_loss: 0.6900 - val_acc: 0.5720\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - acc: 0.5320 - val_loss: 0.6887 - val_acc: 0.6076\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6939 - acc: 0.5128 - val_loss: 0.6923 - val_acc: 0.5088\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6931 - acc: 0.5260 - val_loss: 0.6910 - val_acc: 0.5940\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6928 - acc: 0.5312 - val_loss: 0.6867 - val_acc: 0.5956\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6881 - acc: 0.5432 - val_loss: 0.6825 - val_acc: 0.6052\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6913 - acc: 0.5308 - val_loss: 0.6869 - val_acc: 0.5952\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6873 - acc: 0.5380 - val_loss: 0.6806 - val_acc: 0.6092\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6856 - acc: 0.5544 - val_loss: 0.6848 - val_acc: 0.6208\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6870 - acc: 0.5324 - val_loss: 0.6872 - val_acc: 0.5588\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6831 - acc: 0.5536 - val_loss: 0.6789 - val_acc: 0.5980\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6876 - acc: 0.5608 - val_loss: 0.6891 - val_acc: 0.5284\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6909 - acc: 0.5288 - val_loss: 0.6885 - val_acc: 0.6032\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6857 - acc: 0.5600 - val_loss: 0.6776 - val_acc: 0.6236\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6837 - acc: 0.5552 - val_loss: 0.6762 - val_acc: 0.6136\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6827 - acc: 0.5552 - val_loss: 0.6797 - val_acc: 0.6248\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6832 - acc: 0.5600 - val_loss: 0.6756 - val_acc: 0.6232\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6813 - acc: 0.5540 - val_loss: 0.6809 - val_acc: 0.5784\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6884 - acc: 0.5472 - val_loss: 0.6810 - val_acc: 0.5936\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6895 - acc: 0.5528 - val_loss: 0.6865 - val_acc: 0.5756\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6859 - acc: 0.5392 - val_loss: 0.6805 - val_acc: 0.6220\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6841 - acc: 0.5508 - val_loss: 0.6782 - val_acc: 0.6156\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6855 - acc: 0.5484 - val_loss: 0.6770 - val_acc: 0.6012\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6855 - acc: 0.5576 - val_loss: 0.6817 - val_acc: 0.5832\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6821 - acc: 0.5716 - val_loss: 0.6815 - val_acc: 0.5632\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6862 - acc: 0.5472 - val_loss: 0.6811 - val_acc: 0.5756\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6880 - acc: 0.5556 - val_loss: 0.6809 - val_acc: 0.6304\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6847 - acc: 0.5624 - val_loss: 0.6768 - val_acc: 0.6264\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6814 - acc: 0.5492 - val_loss: 0.6744 - val_acc: 0.6216\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6876 - acc: 0.5448 - val_loss: 0.6776 - val_acc: 0.6220\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6854 - acc: 0.5612 - val_loss: 0.6757 - val_acc: 0.6168\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6783 - acc: 0.5708 - val_loss: 0.6760 - val_acc: 0.5868\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6809 - acc: 0.5560 - val_loss: 0.6750 - val_acc: 0.6044\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6844 - acc: 0.5568 - val_loss: 0.6817 - val_acc: 0.5720\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6887 - acc: 0.5460 - val_loss: 0.6793 - val_acc: 0.6116\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6857 - acc: 0.5456 - val_loss: 0.6814 - val_acc: 0.5832\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6839 - acc: 0.5616 - val_loss: 0.6756 - val_acc: 0.6252\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6779 - acc: 0.5760 - val_loss: 0.6693 - val_acc: 0.6168\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6796 - acc: 0.5680 - val_loss: 0.6744 - val_acc: 0.6260\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6802 - acc: 0.5620 - val_loss: 0.6699 - val_acc: 0.6224\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6837 - acc: 0.5636 - val_loss: 0.6746 - val_acc: 0.6340\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6755 - acc: 0.5676 - val_loss: 0.6666 - val_acc: 0.6204\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6781 - acc: 0.5756 - val_loss: 0.6687 - val_acc: 0.6236\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6817 - acc: 0.5568 - val_loss: 0.6752 - val_acc: 0.6040\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6801 - acc: 0.5616 - val_loss: 0.6703 - val_acc: 0.6108\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6766 - acc: 0.5552 - val_loss: 0.6763 - val_acc: 0.5856\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6788 - acc: 0.5528 - val_loss: 0.6739 - val_acc: 0.6132\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6792 - acc: 0.5736 - val_loss: 0.6705 - val_acc: 0.6244\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6811 - acc: 0.5512 - val_loss: 0.6755 - val_acc: 0.6052\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6792 - acc: 0.5596 - val_loss: 0.6658 - val_acc: 0.6284\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6812 - acc: 0.5472 - val_loss: 0.6789 - val_acc: 0.5884\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6787 - acc: 0.5508 - val_loss: 0.6699 - val_acc: 0.6132\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6785 - acc: 0.5624 - val_loss: 0.6757 - val_acc: 0.6196\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6792 - acc: 0.5696 - val_loss: 0.6785 - val_acc: 0.5768\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6828 - acc: 0.5552 - val_loss: 0.6718 - val_acc: 0.6176\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6769 - acc: 0.5732 - val_loss: 0.6736 - val_acc: 0.5928\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6791 - acc: 0.5656 - val_loss: 0.6720 - val_acc: 0.5904\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6873 - acc: 0.5512 - val_loss: 0.6834 - val_acc: 0.5432\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6850 - acc: 0.5432 - val_loss: 0.6796 - val_acc: 0.6008\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6785 - acc: 0.5692 - val_loss: 0.6702 - val_acc: 0.6244\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6775 - acc: 0.5756 - val_loss: 0.6710 - val_acc: 0.6232\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6726 - acc: 0.5744 - val_loss: 0.6688 - val_acc: 0.6008\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6858 - acc: 0.5716 - val_loss: 0.6733 - val_acc: 0.6060\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5764 - val_loss: 0.6679 - val_acc: 0.6016\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6703 - acc: 0.5660 - val_loss: 0.6666 - val_acc: 0.6304\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6728 - acc: 0.5752 - val_loss: 0.6654 - val_acc: 0.6200\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6730 - acc: 0.5688 - val_loss: 0.6645 - val_acc: 0.6320\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6723 - acc: 0.5784 - val_loss: 0.6660 - val_acc: 0.6124\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6779 - acc: 0.5632 - val_loss: 0.6738 - val_acc: 0.5956\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6771 - acc: 0.5680 - val_loss: 0.6763 - val_acc: 0.5896\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6737 - acc: 0.5512 - val_loss: 0.6651 - val_acc: 0.6344\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6788 - acc: 0.5564 - val_loss: 0.6766 - val_acc: 0.6044\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6748 - acc: 0.5732 - val_loss: 0.6642 - val_acc: 0.6332\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6678 - acc: 0.5912 - val_loss: 0.6679 - val_acc: 0.5956\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6812 - acc: 0.5764 - val_loss: 0.6726 - val_acc: 0.5968\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6868 - acc: 0.5524 - val_loss: 0.6858 - val_acc: 0.5628\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6810 - acc: 0.5624 - val_loss: 0.6721 - val_acc: 0.6184\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - acc: 0.5528 - val_loss: 0.6699 - val_acc: 0.6260\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6782 - acc: 0.5648 - val_loss: 0.6667 - val_acc: 0.6312\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6742 - acc: 0.5760 - val_loss: 0.6697 - val_acc: 0.6092\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6752 - acc: 0.5752 - val_loss: 0.6692 - val_acc: 0.6240\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6737 - acc: 0.5732 - val_loss: 0.6710 - val_acc: 0.5932\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6784 - acc: 0.5692 - val_loss: 0.6750 - val_acc: 0.6024\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6857 - acc: 0.5628 - val_loss: 0.6764 - val_acc: 0.5832\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6752 - acc: 0.5536 - val_loss: 0.6659 - val_acc: 0.6208\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6786 - acc: 0.5772 - val_loss: 0.6759 - val_acc: 0.5700\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6796 - acc: 0.5632 - val_loss: 0.6740 - val_acc: 0.6048\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5784 - val_loss: 0.6752 - val_acc: 0.6144\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6799 - acc: 0.5624 - val_loss: 0.6681 - val_acc: 0.6280\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6732 - acc: 0.5692 - val_loss: 0.6677 - val_acc: 0.6144\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6754 - acc: 0.5680 - val_loss: 0.6691 - val_acc: 0.6084\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6706 - acc: 0.5752 - val_loss: 0.6617 - val_acc: 0.6256\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6742 - acc: 0.5816 - val_loss: 0.6760 - val_acc: 0.5736\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6803 - acc: 0.5632 - val_loss: 0.6717 - val_acc: 0.6192\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6735 - acc: 0.5688 - val_loss: 0.6709 - val_acc: 0.6120\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6753 - acc: 0.5668 - val_loss: 0.6653 - val_acc: 0.6268\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6660 - acc: 0.5888 - val_loss: 0.6601 - val_acc: 0.6372\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6732 - acc: 0.5856 - val_loss: 0.6714 - val_acc: 0.5968\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6723 - acc: 0.5692 - val_loss: 0.6614 - val_acc: 0.6240\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6743 - acc: 0.5788 - val_loss: 0.6704 - val_acc: 0.6020\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6691 - acc: 0.5764 - val_loss: 0.6612 - val_acc: 0.6236\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6833 - acc: 0.5724 - val_loss: 0.6773 - val_acc: 0.5708\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6812 - acc: 0.5552 - val_loss: 0.6752 - val_acc: 0.6176\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6777 - acc: 0.5752 - val_loss: 0.6652 - val_acc: 0.6352\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6672 - acc: 0.5832 - val_loss: 0.6635 - val_acc: 0.6096\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6736 - acc: 0.5876 - val_loss: 0.6689 - val_acc: 0.6136\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6830 - acc: 0.5544 - val_loss: 0.6764 - val_acc: 0.5808\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6760 - acc: 0.5668 - val_loss: 0.6690 - val_acc: 0.6248\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.5804 - val_loss: 0.6636 - val_acc: 0.6192\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6773 - acc: 0.5712 - val_loss: 0.6701 - val_acc: 0.6216\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6715 - acc: 0.5820 - val_loss: 0.6640 - val_acc: 0.6288\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6729 - acc: 0.5772 - val_loss: 0.6671 - val_acc: 0.6340\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6804 - acc: 0.5760 - val_loss: 0.6718 - val_acc: 0.6296\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6740 - acc: 0.5740 - val_loss: 0.6770 - val_acc: 0.6116\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6867 - acc: 0.5892 - val_loss: 0.6624 - val_acc: 0.6292\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6870 - acc: 0.5684 - val_loss: 0.6797 - val_acc: 0.5908\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6772 - acc: 0.5628 - val_loss: 0.6637 - val_acc: 0.6148\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6752 - acc: 0.5748 - val_loss: 0.6748 - val_acc: 0.6168\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6791 - acc: 0.5728 - val_loss: 0.6701 - val_acc: 0.6060\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6820 - acc: 0.5648 - val_loss: 0.6959 - val_acc: 0.5616\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7221 - acc: 0.5668 - val_loss: 0.6740 - val_acc: 0.5804\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6842 - acc: 0.5680 - val_loss: 0.6882 - val_acc: 0.5380\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6880 - acc: 0.5492 - val_loss: 0.6767 - val_acc: 0.5956\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6792 - acc: 0.5540 - val_loss: 0.6714 - val_acc: 0.6132\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.5772 - val_loss: 0.6674 - val_acc: 0.6240\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6733 - acc: 0.5752 - val_loss: 0.6674 - val_acc: 0.6076\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6784 - acc: 0.5736 - val_loss: 0.6707 - val_acc: 0.6352\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6757 - acc: 0.5808 - val_loss: 0.6668 - val_acc: 0.6352\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6752 - acc: 0.5636 - val_loss: 0.6682 - val_acc: 0.6240\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6681 - acc: 0.5780 - val_loss: 0.6596 - val_acc: 0.6272\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6780 - acc: 0.5828 - val_loss: 0.6696 - val_acc: 0.6264\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6683 - acc: 0.5812 - val_loss: 0.6621 - val_acc: 0.6380\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5776 - val_loss: 0.6691 - val_acc: 0.6232\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6717 - acc: 0.5720 - val_loss: 0.6732 - val_acc: 0.6084\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6725 - acc: 0.5744 - val_loss: 0.6627 - val_acc: 0.6344\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6716 - acc: 0.5760 - val_loss: 0.6667 - val_acc: 0.6132\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6692 - acc: 0.5920 - val_loss: 0.6751 - val_acc: 0.5964\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7032 - acc: 0.5636 - val_loss: 0.6869 - val_acc: 0.5168\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6910 - acc: 0.5420 - val_loss: 0.6911 - val_acc: 0.5640\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6825 - acc: 0.5676 - val_loss: 0.6807 - val_acc: 0.6152\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6811 - acc: 0.5740 - val_loss: 0.6761 - val_acc: 0.6328\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.5836 - val_loss: 0.6659 - val_acc: 0.6348\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.5904 - val_loss: 0.6626 - val_acc: 0.6312\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.5788 - val_loss: 0.6690 - val_acc: 0.6160\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6742 - acc: 0.5804 - val_loss: 0.6650 - val_acc: 0.6356\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6776 - acc: 0.5628 - val_loss: 0.6757 - val_acc: 0.5820\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6763 - acc: 0.5804 - val_loss: 0.6753 - val_acc: 0.5552\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6978 - acc: 0.5392 - val_loss: 0.6847 - val_acc: 0.5372\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6924 - acc: 0.5472 - val_loss: 0.6809 - val_acc: 0.6068\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6779 - acc: 0.5740 - val_loss: 0.6729 - val_acc: 0.6312\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6728 - acc: 0.5836 - val_loss: 0.6662 - val_acc: 0.6328\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6724 - acc: 0.5860 - val_loss: 0.6672 - val_acc: 0.6176\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6700 - acc: 0.5796 - val_loss: 0.6641 - val_acc: 0.6372\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6697 - acc: 0.5708 - val_loss: 0.6727 - val_acc: 0.5972\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6808 - acc: 0.5676 - val_loss: 0.6721 - val_acc: 0.6224\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6740 - acc: 0.5764 - val_loss: 0.6657 - val_acc: 0.6216\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6691 - acc: 0.5848 - val_loss: 0.6655 - val_acc: 0.6236\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6783 - acc: 0.5708 - val_loss: 0.6726 - val_acc: 0.6276\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6755 - acc: 0.5628 - val_loss: 0.6702 - val_acc: 0.6044\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6698 - acc: 0.5788 - val_loss: 0.6673 - val_acc: 0.6312\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721 - acc: 0.5812 - val_loss: 0.6825 - val_acc: 0.5664\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6972 - acc: 0.5600 - val_loss: 0.6717 - val_acc: 0.5876\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6896 - acc: 0.5560 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6773 - acc: 0.5488 - val_loss: 0.6742 - val_acc: 0.5868\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6760 - acc: 0.5760 - val_loss: 0.6701 - val_acc: 0.6092\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6715 - acc: 0.5792 - val_loss: 0.6670 - val_acc: 0.6188\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6741 - acc: 0.5792 - val_loss: 0.6643 - val_acc: 0.6316\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6749 - acc: 0.5872 - val_loss: 0.6714 - val_acc: 0.6096\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6758 - acc: 0.5784 - val_loss: 0.6680 - val_acc: 0.6244\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6707 - acc: 0.5976 - val_loss: 0.6671 - val_acc: 0.6008\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6722 - acc: 0.5760 - val_loss: 0.6695 - val_acc: 0.6320\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6702 - acc: 0.5932 - val_loss: 0.6623 - val_acc: 0.6272\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6744 - acc: 0.5696 - val_loss: 0.6707 - val_acc: 0.6228\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.5784 - val_loss: 0.6604 - val_acc: 0.6272\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6681 - acc: 0.5892 - val_loss: 0.6650 - val_acc: 0.6160\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6821 - acc: 0.5620 - val_loss: 0.6710 - val_acc: 0.6364\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6718 - acc: 0.5864 - val_loss: 0.6649 - val_acc: 0.6256\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6752 - acc: 0.5688 - val_loss: 0.6676 - val_acc: 0.6324\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6786 - acc: 0.5720 - val_loss: 0.6768 - val_acc: 0.5736\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6796 - acc: 0.5544 - val_loss: 0.6714 - val_acc: 0.6332\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6731 - acc: 0.5644 - val_loss: 0.6692 - val_acc: 0.6032\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6801 - acc: 0.5776 - val_loss: 0.6755 - val_acc: 0.6248\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6723 - acc: 0.5792 - val_loss: 0.6655 - val_acc: 0.6276\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6696 - acc: 0.5840 - val_loss: 0.6702 - val_acc: 0.5988\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6732 - acc: 0.5836 - val_loss: 0.6639 - val_acc: 0.6276\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6787 - acc: 0.5848 - val_loss: 0.6803 - val_acc: 0.5580\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6799 - acc: 0.5528 - val_loss: 0.6730 - val_acc: 0.6300\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6774 - acc: 0.5720 - val_loss: 0.6678 - val_acc: 0.6164\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6741 - acc: 0.5728 - val_loss: 0.6664 - val_acc: 0.6248\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6800 - acc: 0.5772 - val_loss: 0.6765 - val_acc: 0.5904\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.5756 - val_loss: 0.6625 - val_acc: 0.6304\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6741 - acc: 0.5868 - val_loss: 0.6724 - val_acc: 0.6168\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.5720 - val_loss: 0.6635 - val_acc: 0.6356\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6678 - acc: 0.5896 - val_loss: 0.6641 - val_acc: 0.6184\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.5872 - val_loss: 0.6674 - val_acc: 0.6204\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6741 - acc: 0.5880 - val_loss: 0.6747 - val_acc: 0.5828\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6792 - acc: 0.5712 - val_loss: 0.6800 - val_acc: 0.5504\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6902 - acc: 0.5520 - val_loss: 0.6755 - val_acc: 0.5808\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5688 - val_loss: 0.6709 - val_acc: 0.6308\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6744 - acc: 0.5892 - val_loss: 0.6703 - val_acc: 0.6208\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5772 - val_loss: 0.6631 - val_acc: 0.6296\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - acc: 0.5948 - val_loss: 0.6691 - val_acc: 0.6136\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6763 - acc: 0.5800 - val_loss: 0.6657 - val_acc: 0.6368\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6760 - acc: 0.5828 - val_loss: 0.6717 - val_acc: 0.6052\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6752 - acc: 0.5816 - val_loss: 0.6687 - val_acc: 0.6324\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6754 - acc: 0.5784 - val_loss: 0.6735 - val_acc: 0.6020\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6726 - acc: 0.5736 - val_loss: 0.6625 - val_acc: 0.6332\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6771 - acc: 0.5668 - val_loss: 0.6767 - val_acc: 0.5768\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6796 - acc: 0.5716 - val_loss: 0.6759 - val_acc: 0.6236\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6775 - acc: 0.5756 - val_loss: 0.6771 - val_acc: 0.6072\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6768 - acc: 0.5816 - val_loss: 0.6651 - val_acc: 0.6184\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.5808 - val_loss: 0.6661 - val_acc: 0.6212\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6636 - acc: 0.6040 - val_loss: 0.6574 - val_acc: 0.6352\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6763 - acc: 0.5728 - val_loss: 0.6788 - val_acc: 0.5632\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5712 - val_loss: 0.6699 - val_acc: 0.6264\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.5860 - val_loss: 0.6654 - val_acc: 0.6180\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.5744 - val_loss: 0.6643 - val_acc: 0.6376\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6629 - acc: 0.6008 - val_loss: 0.6639 - val_acc: 0.6072\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6765 - acc: 0.5788 - val_loss: 0.6716 - val_acc: 0.6212\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6726 - acc: 0.6016 - val_loss: 0.6642 - val_acc: 0.6232\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6738 - acc: 0.5744 - val_loss: 0.6695 - val_acc: 0.6336\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6619 - acc: 0.5924 - val_loss: 0.6553 - val_acc: 0.6292\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6813 - acc: 0.5864 - val_loss: 0.6790 - val_acc: 0.5840\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6759 - acc: 0.5756 - val_loss: 0.6615 - val_acc: 0.6396\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6822 - acc: 0.5688 - val_loss: 0.6776 - val_acc: 0.6208\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6760 - acc: 0.5828 - val_loss: 0.6626 - val_acc: 0.6356\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6737 - acc: 0.5884 - val_loss: 0.6676 - val_acc: 0.6220\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6697 - acc: 0.5816 - val_loss: 0.6625 - val_acc: 0.6276\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.5900 - val_loss: 0.6733 - val_acc: 0.6004\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6724 - acc: 0.5756 - val_loss: 0.6636 - val_acc: 0.6316\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6723 - acc: 0.5852 - val_loss: 0.6706 - val_acc: 0.5964\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - acc: 0.5828 - val_loss: 0.6730 - val_acc: 0.5608\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - acc: 0.5588 - val_loss: 0.6832 - val_acc: 0.5688\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6805 - acc: 0.5588 - val_loss: 0.6734 - val_acc: 0.6164\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6772 - acc: 0.5732 - val_loss: 0.6656 - val_acc: 0.6312\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.5924 - val_loss: 0.6630 - val_acc: 0.6304\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6684 - acc: 0.6036 - val_loss: 0.6683 - val_acc: 0.6004\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6727 - acc: 0.5844 - val_loss: 0.6813 - val_acc: 0.5276\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7056 - acc: 0.5364 - val_loss: 0.6813 - val_acc: 0.5412\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6806 - acc: 0.5496 - val_loss: 0.6814 - val_acc: 0.5788\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6721 - acc: 0.5836 - val_loss: 0.6633 - val_acc: 0.6144\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6718 - acc: 0.5856 - val_loss: 0.6680 - val_acc: 0.6268\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6724 - acc: 0.5856 - val_loss: 0.6673 - val_acc: 0.6204\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6657 - acc: 0.5932 - val_loss: 0.6640 - val_acc: 0.6256\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6675 - acc: 0.6088 - val_loss: 0.6605 - val_acc: 0.6336\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6775 - acc: 0.5748 - val_loss: 0.6769 - val_acc: 0.5680\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6806 - acc: 0.5636 - val_loss: 0.6761 - val_acc: 0.6200\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6772 - acc: 0.5752 - val_loss: 0.6723 - val_acc: 0.6152\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6754 - acc: 0.5892 - val_loss: 0.6700 - val_acc: 0.5972\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6657 - acc: 0.5932 - val_loss: 0.6630 - val_acc: 0.6144\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6784 - acc: 0.5864 - val_loss: 0.6783 - val_acc: 0.5648\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6752 - acc: 0.5824 - val_loss: 0.6691 - val_acc: 0.6260\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6763 - acc: 0.5768 - val_loss: 0.6704 - val_acc: 0.6016\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6730 - acc: 0.5836 - val_loss: 0.6681 - val_acc: 0.6072\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6797 - acc: 0.5788 - val_loss: 0.7023 - val_acc: 0.5512\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7159 - acc: 0.5612 - val_loss: 0.6669 - val_acc: 0.6288\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6724 - acc: 0.5844 - val_loss: 0.6675 - val_acc: 0.6324\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6674 - acc: 0.5848 - val_loss: 0.6629 - val_acc: 0.6312\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6668 - acc: 0.5888 - val_loss: 0.6644 - val_acc: 0.6208\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6695 - acc: 0.5956 - val_loss: 0.6668 - val_acc: 0.6176\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6684 - acc: 0.5932 - val_loss: 0.6730 - val_acc: 0.5796\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6725 - acc: 0.5916 - val_loss: 0.6724 - val_acc: 0.5912\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6801 - acc: 0.5860 - val_loss: 0.6748 - val_acc: 0.6132\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6755 - acc: 0.5828 - val_loss: 0.6656 - val_acc: 0.6324\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6676 - acc: 0.5880 - val_loss: 0.6614 - val_acc: 0.6208\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6671 - acc: 0.5832 - val_loss: 0.6637 - val_acc: 0.6352\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6673 - acc: 0.5924 - val_loss: 0.6621 - val_acc: 0.6364\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6646 - acc: 0.5896 - val_loss: 0.6626 - val_acc: 0.6180\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6770 - acc: 0.5784 - val_loss: 0.6689 - val_acc: 0.6308\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6728 - acc: 0.5720 - val_loss: 0.6749 - val_acc: 0.5860\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6799 - acc: 0.5856 - val_loss: 0.6730 - val_acc: 0.6016\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6936 - acc: 0.5668 - val_loss: 0.6781 - val_acc: 0.5848\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6736 - acc: 0.5600 - val_loss: 0.6683 - val_acc: 0.6368\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6719 - acc: 0.5888 - val_loss: 0.6633 - val_acc: 0.6332\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5920 - val_loss: 0.6703 - val_acc: 0.6340\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6699 - acc: 0.5884 - val_loss: 0.6608 - val_acc: 0.6336\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6692 - acc: 0.5936 - val_loss: 0.6728 - val_acc: 0.5756\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6688 - acc: 0.5788 - val_loss: 0.6681 - val_acc: 0.6260\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6685 - acc: 0.5908 - val_loss: 0.6654 - val_acc: 0.6128\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6669 - acc: 0.5884 - val_loss: 0.6617 - val_acc: 0.6212\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6694 - acc: 0.5868 - val_loss: 0.6666 - val_acc: 0.6152\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6687 - acc: 0.5956 - val_loss: 0.6617 - val_acc: 0.6200\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6660 - acc: 0.6112 - val_loss: 0.6615 - val_acc: 0.6192\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6672 - acc: 0.5952 - val_loss: 0.6650 - val_acc: 0.6168\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6695 - acc: 0.5736 - val_loss: 0.6753 - val_acc: 0.5732\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6809 - acc: 0.5800 - val_loss: 0.6737 - val_acc: 0.5976\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6861 - acc: 0.5604 - val_loss: 0.6845 - val_acc: 0.5604\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6825 - acc: 0.5692 - val_loss: 0.6668 - val_acc: 0.6368\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6684 - acc: 0.5876 - val_loss: 0.6624 - val_acc: 0.6296\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6702 - acc: 0.5764 - val_loss: 0.6629 - val_acc: 0.6252\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.5940 - val_loss: 0.6764 - val_acc: 0.5424\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7003 - acc: 0.5500 - val_loss: 0.6904 - val_acc: 0.5128\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6936 - acc: 0.5452 - val_loss: 0.6824 - val_acc: 0.5936\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6758 - acc: 0.5824 - val_loss: 0.6692 - val_acc: 0.6068\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6680 - acc: 0.5856 - val_loss: 0.6660 - val_acc: 0.6136\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6682 - acc: 0.5908 - val_loss: 0.6604 - val_acc: 0.6276\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6704 - acc: 0.5928 - val_loss: 0.6665 - val_acc: 0.6348\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - acc: 0.5828 - val_loss: 0.6634 - val_acc: 0.6128\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6719 - acc: 0.5964 - val_loss: 0.6655 - val_acc: 0.5996\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6808 - acc: 0.5748 - val_loss: 0.6822 - val_acc: 0.5276\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6852 - acc: 0.5448 - val_loss: 0.6804 - val_acc: 0.6004\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6742 - acc: 0.5784 - val_loss: 0.6665 - val_acc: 0.6384\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6656 - acc: 0.5924 - val_loss: 0.6608 - val_acc: 0.6204\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6778 - acc: 0.5884 - val_loss: 0.6737 - val_acc: 0.6040\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6810 - acc: 0.5668 - val_loss: 0.6705 - val_acc: 0.6176\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6726 - acc: 0.5948 - val_loss: 0.6663 - val_acc: 0.6112\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6679 - acc: 0.5960 - val_loss: 0.6595 - val_acc: 0.6272\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6704 - acc: 0.6000 - val_loss: 0.6708 - val_acc: 0.6088\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5824 - val_loss: 0.6644 - val_acc: 0.6360\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6741 - acc: 0.5868 - val_loss: 0.6711 - val_acc: 0.6144\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6696 - acc: 0.5852 - val_loss: 0.6641 - val_acc: 0.6096\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6857 - acc: 0.5876 - val_loss: 0.6821 - val_acc: 0.5348\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6845 - acc: 0.5496 - val_loss: 0.6820 - val_acc: 0.6084\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6773 - acc: 0.5732 - val_loss: 0.6647 - val_acc: 0.6232\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6696 - acc: 0.5916 - val_loss: 0.6634 - val_acc: 0.6220\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - acc: 0.5956 - val_loss: 0.6716 - val_acc: 0.5896\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6788 - acc: 0.5848 - val_loss: 0.6714 - val_acc: 0.5684\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6827 - acc: 0.5716 - val_loss: 0.6814 - val_acc: 0.5804\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6749 - acc: 0.5788 - val_loss: 0.6662 - val_acc: 0.6224\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6748 - acc: 0.5880 - val_loss: 0.6654 - val_acc: 0.6276\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6636 - acc: 0.6004 - val_loss: 0.6572 - val_acc: 0.6252\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6658 - acc: 0.5880 - val_loss: 0.6648 - val_acc: 0.6148\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5840 - val_loss: 0.6638 - val_acc: 0.6308\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6755 - acc: 0.5876 - val_loss: 0.6689 - val_acc: 0.6256\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6673 - acc: 0.5964 - val_loss: 0.6616 - val_acc: 0.6284\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6782 - acc: 0.5736 - val_loss: 0.6781 - val_acc: 0.5836\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6704 - acc: 0.5900 - val_loss: 0.6620 - val_acc: 0.6384\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6667 - acc: 0.6056 - val_loss: 0.6598 - val_acc: 0.6216\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6717 - acc: 0.6016 - val_loss: 0.6684 - val_acc: 0.6304\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6730 - acc: 0.5732 - val_loss: 0.6702 - val_acc: 0.6088\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6678 - acc: 0.5864 - val_loss: 0.6606 - val_acc: 0.6328\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6676 - acc: 0.5936 - val_loss: 0.6727 - val_acc: 0.5968\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6740 - acc: 0.5788 - val_loss: 0.6683 - val_acc: 0.6216\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6758 - acc: 0.5912 - val_loss: 0.6650 - val_acc: 0.6188\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6768 - acc: 0.5660 - val_loss: 0.6714 - val_acc: 0.6256\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6028 - val_loss: 0.6608 - val_acc: 0.6416\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6689 - acc: 0.5916 - val_loss: 0.6636 - val_acc: 0.6276\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6641 - acc: 0.6044 - val_loss: 0.6596 - val_acc: 0.6272\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6651 - acc: 0.5992 - val_loss: 0.6684 - val_acc: 0.5920\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - acc: 0.5788 - val_loss: 0.6713 - val_acc: 0.6060\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6830 - acc: 0.5760 - val_loss: 0.6766 - val_acc: 0.5888\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6751 - acc: 0.5696 - val_loss: 0.6655 - val_acc: 0.6288\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6745 - acc: 0.5828 - val_loss: 0.6672 - val_acc: 0.6196\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5848 - val_loss: 0.6653 - val_acc: 0.6304\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6664 - acc: 0.5836 - val_loss: 0.6705 - val_acc: 0.5872\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6753 - acc: 0.5840 - val_loss: 0.6727 - val_acc: 0.6084\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6828 - acc: 0.5732 - val_loss: 0.6809 - val_acc: 0.5932\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5700 - val_loss: 0.6638 - val_acc: 0.6228\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6650 - acc: 0.5880 - val_loss: 0.6636 - val_acc: 0.6168\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6669 - acc: 0.5888 - val_loss: 0.6767 - val_acc: 0.5680\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6754 - acc: 0.5816 - val_loss: 0.6711 - val_acc: 0.6068\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6767 - acc: 0.5820 - val_loss: 0.6801 - val_acc: 0.5996\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6704 - acc: 0.5812 - val_loss: 0.6615 - val_acc: 0.6168\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.5912 - val_loss: 0.6684 - val_acc: 0.6240\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - acc: 0.6152 - val_loss: 0.6586 - val_acc: 0.6368\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6755 - acc: 0.5824 - val_loss: 0.6708 - val_acc: 0.6232\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6734 - acc: 0.5724 - val_loss: 0.6650 - val_acc: 0.6348\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6619 - acc: 0.6080 - val_loss: 0.6557 - val_acc: 0.6252\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6743 - acc: 0.5984 - val_loss: 0.6694 - val_acc: 0.6252\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.5888 - val_loss: 0.6629 - val_acc: 0.6272\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6737 - acc: 0.5932 - val_loss: 0.6737 - val_acc: 0.5832\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6809 - acc: 0.5840 - val_loss: 0.6740 - val_acc: 0.5844\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6770 - acc: 0.5792 - val_loss: 0.6823 - val_acc: 0.5892\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6698 - acc: 0.5804 - val_loss: 0.6641 - val_acc: 0.6268\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6734 - acc: 0.5856 - val_loss: 0.6657 - val_acc: 0.6204\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6730 - acc: 0.5980 - val_loss: 0.6682 - val_acc: 0.6152\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6719 - acc: 0.5808 - val_loss: 0.6666 - val_acc: 0.6208\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6727 - acc: 0.5856 - val_loss: 0.6697 - val_acc: 0.6092\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6689 - acc: 0.5896 - val_loss: 0.6637 - val_acc: 0.6200\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6723 - acc: 0.5904 - val_loss: 0.6706 - val_acc: 0.5944\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6722 - acc: 0.5848 - val_loss: 0.6628 - val_acc: 0.6228\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6707 - acc: 0.5836 - val_loss: 0.6740 - val_acc: 0.5840\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6775 - acc: 0.5740 - val_loss: 0.6694 - val_acc: 0.6100\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6734 - acc: 0.5748 - val_loss: 0.6727 - val_acc: 0.6144\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6701 - acc: 0.5980 - val_loss: 0.6589 - val_acc: 0.6276\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6690 - acc: 0.5952 - val_loss: 0.6725 - val_acc: 0.5900\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6777 - acc: 0.5772 - val_loss: 0.6703 - val_acc: 0.6112\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6759 - acc: 0.6024 - val_loss: 0.6786 - val_acc: 0.6296\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6787 - acc: 0.5660 - val_loss: 0.6680 - val_acc: 0.6252\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6691 - acc: 0.5904 - val_loss: 0.6593 - val_acc: 0.6368\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6651 - acc: 0.6040 - val_loss: 0.6620 - val_acc: 0.6328\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6748 - acc: 0.5824 - val_loss: 0.6660 - val_acc: 0.6104\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6831 - acc: 0.5728 - val_loss: 0.6734 - val_acc: 0.5928\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6759 - acc: 0.5796 - val_loss: 0.6693 - val_acc: 0.6108\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6798 - acc: 0.5780 - val_loss: 0.6724 - val_acc: 0.6056\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6665 - acc: 0.5872 - val_loss: 0.6604 - val_acc: 0.6288\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6666 - acc: 0.5876 - val_loss: 0.6720 - val_acc: 0.5860\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6749 - acc: 0.5944 - val_loss: 0.6703 - val_acc: 0.6020\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6747 - acc: 0.5916 - val_loss: 0.6756 - val_acc: 0.6060\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6741 - acc: 0.5872 - val_loss: 0.6648 - val_acc: 0.6292\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6752 - acc: 0.5728 - val_loss: 0.6723 - val_acc: 0.6144\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6665 - acc: 0.5940 - val_loss: 0.6593 - val_acc: 0.6284\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6705 - acc: 0.5832 - val_loss: 0.6720 - val_acc: 0.5936\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6775 - acc: 0.5800 - val_loss: 0.6691 - val_acc: 0.6008\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6823 - acc: 0.5684 - val_loss: 0.6784 - val_acc: 0.5928\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6703 - acc: 0.5816 - val_loss: 0.6615 - val_acc: 0.6180\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6791 - acc: 0.5884 - val_loss: 0.6760 - val_acc: 0.6208\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6693 - acc: 0.6028 - val_loss: 0.6585 - val_acc: 0.6304\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6738 - acc: 0.5848 - val_loss: 0.6693 - val_acc: 0.6148\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6688 - acc: 0.5920 - val_loss: 0.6616 - val_acc: 0.6244\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6772 - acc: 0.5768 - val_loss: 0.6718 - val_acc: 0.6216\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6780 - acc: 0.5776 - val_loss: 0.6694 - val_acc: 0.6304\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6677 - acc: 0.5988 - val_loss: 0.6632 - val_acc: 0.6108\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6750 - acc: 0.5880 - val_loss: 0.6683 - val_acc: 0.6140\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6726 - acc: 0.5808 - val_loss: 0.6660 - val_acc: 0.6224\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6679 - acc: 0.5928 - val_loss: 0.6650 - val_acc: 0.6200\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6766 - acc: 0.5864 - val_loss: 0.6742 - val_acc: 0.5976\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6728 - acc: 0.5940 - val_loss: 0.6639 - val_acc: 0.6216\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6714 - acc: 0.5836 - val_loss: 0.6711 - val_acc: 0.6020\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6735 - acc: 0.5884 - val_loss: 0.6686 - val_acc: 0.6076\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6742 - acc: 0.5864 - val_loss: 0.6761 - val_acc: 0.6132\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6735 - acc: 0.5928 - val_loss: 0.6624 - val_acc: 0.6228\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6811 - acc: 0.5688 - val_loss: 0.6760 - val_acc: 0.6148\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.5940 - val_loss: 0.6598 - val_acc: 0.6308\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.5908 - val_loss: 0.6767 - val_acc: 0.5648\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6799 - acc: 0.5828 - val_loss: 0.6740 - val_acc: 0.6064\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6808 - acc: 0.5788 - val_loss: 0.6770 - val_acc: 0.6212\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5960 - val_loss: 0.6713 - val_acc: 0.6360\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6876 - acc: 0.5908 - val_loss: 0.6670 - val_acc: 0.6112\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6726 - acc: 0.5908 - val_loss: 0.6660 - val_acc: 0.6232\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6719 - acc: 0.5880 - val_loss: 0.6674 - val_acc: 0.6308\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.5904 - val_loss: 0.6597 - val_acc: 0.6352\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6726 - acc: 0.5748 - val_loss: 0.6744 - val_acc: 0.6092\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6767 - acc: 0.5728 - val_loss: 0.6696 - val_acc: 0.6280\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6724 - acc: 0.5796 - val_loss: 0.6625 - val_acc: 0.6296\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6737 - acc: 0.5876 - val_loss: 0.6670 - val_acc: 0.6304\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6741 - acc: 0.5804 - val_loss: 0.6741 - val_acc: 0.5532\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6840 - acc: 0.5764 - val_loss: 0.7053 - val_acc: 0.5104\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7186 - acc: 0.5468 - val_loss: 0.6724 - val_acc: 0.6168\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6798 - acc: 0.5840 - val_loss: 0.6772 - val_acc: 0.6340\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.5952 - val_loss: 0.6634 - val_acc: 0.6340\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6607 - acc: 0.6180 - val_loss: 0.6617 - val_acc: 0.6364\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6735 - acc: 0.5908 - val_loss: 0.6653 - val_acc: 0.6328\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6721 - acc: 0.5816 - val_loss: 0.6703 - val_acc: 0.6156\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6659 - acc: 0.5976 - val_loss: 0.6597 - val_acc: 0.6212\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6678 - acc: 0.5892 - val_loss: 0.6776 - val_acc: 0.5640\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6733 - acc: 0.5792 - val_loss: 0.6670 - val_acc: 0.6168\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - acc: 0.5856 - val_loss: 0.6685 - val_acc: 0.6312\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6775 - acc: 0.5744 - val_loss: 0.6656 - val_acc: 0.6172\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6648 - acc: 0.5912 - val_loss: 0.6675 - val_acc: 0.6188\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6717 - acc: 0.5924 - val_loss: 0.6603 - val_acc: 0.6376\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6702 - acc: 0.6004 - val_loss: 0.6656 - val_acc: 0.6160\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6691 - acc: 0.5860 - val_loss: 0.6612 - val_acc: 0.6124\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6768 - acc: 0.5696 - val_loss: 0.6715 - val_acc: 0.5868\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6759 - acc: 0.5824 - val_loss: 0.6667 - val_acc: 0.6084\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6756 - acc: 0.5880 - val_loss: 0.6773 - val_acc: 0.6080\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6752 - acc: 0.5760 - val_loss: 0.6653 - val_acc: 0.6340\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6674 - acc: 0.5992 - val_loss: 0.6578 - val_acc: 0.6380\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6725 - acc: 0.5872 - val_loss: 0.6711 - val_acc: 0.5992\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6747 - acc: 0.5868 - val_loss: 0.6619 - val_acc: 0.6276\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6766 - acc: 0.5928 - val_loss: 0.6729 - val_acc: 0.6004\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6704 - acc: 0.5896 - val_loss: 0.6635 - val_acc: 0.6140\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6705 - acc: 0.5916 - val_loss: 0.6683 - val_acc: 0.6148\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6740 - acc: 0.5816 - val_loss: 0.6645 - val_acc: 0.6256\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6674 - acc: 0.5928 - val_loss: 0.6640 - val_acc: 0.6160\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6673 - acc: 0.5988 - val_loss: 0.6580 - val_acc: 0.6320\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6701 - acc: 0.6004 - val_loss: 0.6704 - val_acc: 0.5904\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6697 - acc: 0.5932 - val_loss: 0.6656 - val_acc: 0.6024\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6769 - acc: 0.5844 - val_loss: 0.6762 - val_acc: 0.5804\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6800 - acc: 0.5776 - val_loss: 0.6754 - val_acc: 0.6220\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6744 - acc: 0.5924 - val_loss: 0.6639 - val_acc: 0.6304\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6725 - acc: 0.5952 - val_loss: 0.6617 - val_acc: 0.6220\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.5872 - val_loss: 0.6642 - val_acc: 0.6332\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6669 - acc: 0.6056 - val_loss: 0.6578 - val_acc: 0.6296\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6693 - acc: 0.6000 - val_loss: 0.6654 - val_acc: 0.6156\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6686 - acc: 0.6028 - val_loss: 0.6608 - val_acc: 0.6168\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6819 - acc: 0.5780 - val_loss: 0.6796 - val_acc: 0.5724\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6778 - acc: 0.5628 - val_loss: 0.6750 - val_acc: 0.6264\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6736 - acc: 0.5924 - val_loss: 0.6596 - val_acc: 0.6380\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.5940 - val_loss: 0.6651 - val_acc: 0.6220\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6670 - acc: 0.5896 - val_loss: 0.6616 - val_acc: 0.6116\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6735 - acc: 0.5916 - val_loss: 0.6770 - val_acc: 0.5700\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6746 - acc: 0.5800 - val_loss: 0.6700 - val_acc: 0.6116\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6733 - acc: 0.5912 - val_loss: 0.6662 - val_acc: 0.6104\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.5940 - val_loss: 0.6676 - val_acc: 0.6136\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6737 - acc: 0.5892 - val_loss: 0.6682 - val_acc: 0.6228\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6730 - acc: 0.5832 - val_loss: 0.6644 - val_acc: 0.6320\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6751 - acc: 0.5912 - val_loss: 0.6650 - val_acc: 0.6344\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.5980 - val_loss: 0.6616 - val_acc: 0.6252\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6024 - val_loss: 0.6655 - val_acc: 0.6124\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6804 - acc: 0.5700 - val_loss: 0.6802 - val_acc: 0.5668\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6795 - acc: 0.5632 - val_loss: 0.6698 - val_acc: 0.6300\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5936 - val_loss: 0.6598 - val_acc: 0.6364\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6658 - acc: 0.5948 - val_loss: 0.6674 - val_acc: 0.6144\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6676 - acc: 0.5936 - val_loss: 0.6641 - val_acc: 0.6116\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6828 - acc: 0.5792 - val_loss: 0.6829 - val_acc: 0.5432\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6766 - acc: 0.5600 - val_loss: 0.6752 - val_acc: 0.6028\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6773 - acc: 0.5740 - val_loss: 0.6700 - val_acc: 0.6264\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6748 - acc: 0.5784 - val_loss: 0.6709 - val_acc: 0.5924\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6791 - acc: 0.5808 - val_loss: 0.6691 - val_acc: 0.5972\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6829 - acc: 0.5540 - val_loss: 0.6841 - val_acc: 0.5740\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6772 - acc: 0.5752 - val_loss: 0.6684 - val_acc: 0.6148\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6725 - acc: 0.5788 - val_loss: 0.6921 - val_acc: 0.5244\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7114 - acc: 0.5644 - val_loss: 0.6918 - val_acc: 0.5264\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6940 - acc: 0.5560 - val_loss: 0.6749 - val_acc: 0.6260\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6782 - acc: 0.5680 - val_loss: 0.6743 - val_acc: 0.6320\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.6036 - val_loss: 0.6619 - val_acc: 0.6388\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6660 - acc: 0.6028 - val_loss: 0.6598 - val_acc: 0.6416\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6657 - acc: 0.5924 - val_loss: 0.6629 - val_acc: 0.6264\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6747 - acc: 0.5824 - val_loss: 0.6667 - val_acc: 0.6256\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6732 - acc: 0.5804 - val_loss: 0.6628 - val_acc: 0.6340\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6676 - acc: 0.6052 - val_loss: 0.6617 - val_acc: 0.6248\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6723 - acc: 0.5860 - val_loss: 0.6689 - val_acc: 0.6148\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6787 - acc: 0.5836 - val_loss: 0.6642 - val_acc: 0.6336\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.5948 - val_loss: 0.6607 - val_acc: 0.6280\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6696 - acc: 0.6072 - val_loss: 0.6650 - val_acc: 0.6380\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6631 - acc: 0.6060 - val_loss: 0.6558 - val_acc: 0.6316\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6665 - acc: 0.5980 - val_loss: 0.6630 - val_acc: 0.6332\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6767 - acc: 0.5812 - val_loss: 0.6728 - val_acc: 0.6284\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6645 - acc: 0.6016 - val_loss: 0.6554 - val_acc: 0.6244\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6828 - acc: 0.5776 - val_loss: 0.6821 - val_acc: 0.5300\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6886 - acc: 0.5492 - val_loss: 0.6868 - val_acc: 0.5988\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6762 - acc: 0.5900 - val_loss: 0.6665 - val_acc: 0.6340\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6752 - acc: 0.5992 - val_loss: 0.6661 - val_acc: 0.6088\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6631 - acc: 0.5988 - val_loss: 0.6624 - val_acc: 0.6104\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6700 - acc: 0.5908 - val_loss: 0.6753 - val_acc: 0.5808\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6732 - acc: 0.5764 - val_loss: 0.6707 - val_acc: 0.6156\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6688 - acc: 0.5956 - val_loss: 0.6664 - val_acc: 0.6344\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.5900 - val_loss: 0.6602 - val_acc: 0.6268\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6668 - acc: 0.5976 - val_loss: 0.6607 - val_acc: 0.6304\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6750 - acc: 0.5896 - val_loss: 0.6681 - val_acc: 0.6224\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6813 - acc: 0.5744 - val_loss: 0.6710 - val_acc: 0.6240\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6736 - acc: 0.5804 - val_loss: 0.6658 - val_acc: 0.6220\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6675 - acc: 0.5840 - val_loss: 0.6618 - val_acc: 0.6308\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6747 - acc: 0.5876 - val_loss: 0.6676 - val_acc: 0.6216\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6694 - acc: 0.5832 - val_loss: 0.6603 - val_acc: 0.6312\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - acc: 0.5848 - val_loss: 0.6636 - val_acc: 0.6156\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6706 - acc: 0.5940 - val_loss: 0.6695 - val_acc: 0.5784\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6892 - acc: 0.5616 - val_loss: 0.6912 - val_acc: 0.5304\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7012 - acc: 0.5532 - val_loss: 0.6751 - val_acc: 0.5924\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6803 - acc: 0.5728 - val_loss: 0.6842 - val_acc: 0.5944\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6776 - acc: 0.5820 - val_loss: 0.6657 - val_acc: 0.6344\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6723 - acc: 0.5836 - val_loss: 0.6681 - val_acc: 0.6112\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.5792 - val_loss: 0.6618 - val_acc: 0.6324\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - acc: 0.5892 - val_loss: 0.6753 - val_acc: 0.5920\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6768 - acc: 0.5676 - val_loss: 0.6619 - val_acc: 0.6288\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6726 - acc: 0.5948 - val_loss: 0.6702 - val_acc: 0.6032\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6665 - acc: 0.5968 - val_loss: 0.6589 - val_acc: 0.6240\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6680 - acc: 0.5884 - val_loss: 0.6799 - val_acc: 0.5516\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6786 - acc: 0.5856 - val_loss: 0.6687 - val_acc: 0.5824\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6860 - acc: 0.5676 - val_loss: 0.6820 - val_acc: 0.5524\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6760 - acc: 0.5600 - val_loss: 0.6748 - val_acc: 0.5960\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6736 - acc: 0.5828 - val_loss: 0.6661 - val_acc: 0.6260\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6727 - acc: 0.5880 - val_loss: 0.6648 - val_acc: 0.6352\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.5824 - val_loss: 0.6632 - val_acc: 0.6380\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6654 - acc: 0.5904 - val_loss: 0.6614 - val_acc: 0.6400\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6663 - acc: 0.6052 - val_loss: 0.6578 - val_acc: 0.6368\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6703 - acc: 0.6028 - val_loss: 0.6613 - val_acc: 0.6324\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6651 - acc: 0.6004 - val_loss: 0.6620 - val_acc: 0.6116\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.5980 - val_loss: 0.6660 - val_acc: 0.6048\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6738 - acc: 0.5844 - val_loss: 0.6743 - val_acc: 0.6004\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6794 - acc: 0.5768 - val_loss: 0.6704 - val_acc: 0.6148\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - acc: 0.6004 - val_loss: 0.6602 - val_acc: 0.6240\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6722 - acc: 0.5936 - val_loss: 0.6789 - val_acc: 0.6228\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6962 - acc: 0.5872 - val_loss: 0.6589 - val_acc: 0.6272\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.5952 - val_loss: 0.6728 - val_acc: 0.5996\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6771 - acc: 0.5792 - val_loss: 0.6693 - val_acc: 0.6164\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6705 - acc: 0.5984 - val_loss: 0.6605 - val_acc: 0.6276\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6672 - acc: 0.5960 - val_loss: 0.6607 - val_acc: 0.6260\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6732 - acc: 0.5968 - val_loss: 0.6644 - val_acc: 0.6220\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6726 - acc: 0.5920 - val_loss: 0.6736 - val_acc: 0.5880\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6736 - acc: 0.5916 - val_loss: 0.6651 - val_acc: 0.6088\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6684 - acc: 0.5856 - val_loss: 0.6798 - val_acc: 0.5492\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6781 - acc: 0.5688 - val_loss: 0.6718 - val_acc: 0.6264\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6736 - acc: 0.5888 - val_loss: 0.6659 - val_acc: 0.6204\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6705 - acc: 0.5900 - val_loss: 0.6619 - val_acc: 0.6340\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6700 - acc: 0.5792 - val_loss: 0.6700 - val_acc: 0.5956\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6683 - acc: 0.5996 - val_loss: 0.6642 - val_acc: 0.6084\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6763 - acc: 0.5780 - val_loss: 0.6837 - val_acc: 0.5288\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6862 - acc: 0.5592 - val_loss: 0.6806 - val_acc: 0.6208\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - acc: 0.5940 - val_loss: 0.6615 - val_acc: 0.6348\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6679 - acc: 0.6072 - val_loss: 0.6642 - val_acc: 0.6212\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6675 - acc: 0.5936 - val_loss: 0.6674 - val_acc: 0.6400\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6689 - acc: 0.5840 - val_loss: 0.6705 - val_acc: 0.5680\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6946 - acc: 0.5464 - val_loss: 0.7103 - val_acc: 0.5120\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7185 - acc: 0.5500 - val_loss: 0.6653 - val_acc: 0.6276\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6816 - acc: 0.5740 - val_loss: 0.6834 - val_acc: 0.5876\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6770 - acc: 0.5660 - val_loss: 0.6754 - val_acc: 0.6180\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6766 - acc: 0.5812 - val_loss: 0.6675 - val_acc: 0.6304\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6759 - acc: 0.5688 - val_loss: 0.6699 - val_acc: 0.6064\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6720 - acc: 0.5916 - val_loss: 0.6650 - val_acc: 0.6148\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6805 - acc: 0.5752 - val_loss: 0.6755 - val_acc: 0.5900\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6757 - acc: 0.5624 - val_loss: 0.6661 - val_acc: 0.6336\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6670 - acc: 0.5876 - val_loss: 0.6623 - val_acc: 0.6260\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6700 - acc: 0.5964 - val_loss: 0.6635 - val_acc: 0.6200\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.5948 - val_loss: 0.6602 - val_acc: 0.6380\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6732 - acc: 0.5916 - val_loss: 0.6675 - val_acc: 0.6076\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - acc: 0.5936 - val_loss: 0.6613 - val_acc: 0.6280\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6699 - acc: 0.5960 - val_loss: 0.6717 - val_acc: 0.5908\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6675 - acc: 0.5840 - val_loss: 0.6586 - val_acc: 0.6312\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6667 - acc: 0.6008 - val_loss: 0.6695 - val_acc: 0.6028\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5940 - val_loss: 0.6631 - val_acc: 0.6056\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6736 - acc: 0.5752 - val_loss: 0.6873 - val_acc: 0.5164\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6898 - acc: 0.5516 - val_loss: 0.6774 - val_acc: 0.6124\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6040 - val_loss: 0.6662 - val_acc: 0.6136\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6771 - acc: 0.5828 - val_loss: 0.6769 - val_acc: 0.5960\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6742 - acc: 0.5680 - val_loss: 0.6654 - val_acc: 0.6296\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.5792 - val_loss: 0.6655 - val_acc: 0.6380\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.5840 - val_loss: 0.6631 - val_acc: 0.6308\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.5872 - val_loss: 0.6633 - val_acc: 0.6232\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6754 - acc: 0.5784 - val_loss: 0.6665 - val_acc: 0.6284\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6649 - acc: 0.6004 - val_loss: 0.6624 - val_acc: 0.6120\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6640 - acc: 0.5816 - val_loss: 0.6626 - val_acc: 0.6312\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6642 - acc: 0.6108 - val_loss: 0.6612 - val_acc: 0.6140\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6647 - acc: 0.6028 - val_loss: 0.6676 - val_acc: 0.5924\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6833 - acc: 0.5800 - val_loss: 0.6841 - val_acc: 0.5104\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6840 - acc: 0.5472 - val_loss: 0.6848 - val_acc: 0.6008\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6748 - acc: 0.5920 - val_loss: 0.6625 - val_acc: 0.6288\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6738 - acc: 0.5840 - val_loss: 0.6697 - val_acc: 0.6024\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6748 - acc: 0.5848 - val_loss: 0.6639 - val_acc: 0.6328\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6731 - acc: 0.5820 - val_loss: 0.6710 - val_acc: 0.5956\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6736 - acc: 0.5836 - val_loss: 0.6689 - val_acc: 0.6204\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - acc: 0.5912 - val_loss: 0.6681 - val_acc: 0.6076\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6671 - acc: 0.5928 - val_loss: 0.6605 - val_acc: 0.6260\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6776 - acc: 0.5828 - val_loss: 0.6736 - val_acc: 0.5824\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6761 - acc: 0.5812 - val_loss: 0.6729 - val_acc: 0.6152\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6778 - acc: 0.5900 - val_loss: 0.6704 - val_acc: 0.6184\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6718 - acc: 0.5756 - val_loss: 0.6625 - val_acc: 0.6300\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6691 - acc: 0.6100 - val_loss: 0.6597 - val_acc: 0.6204\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6697 - acc: 0.5916 - val_loss: 0.6649 - val_acc: 0.6164\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.5976 - val_loss: 0.6653 - val_acc: 0.6068\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6665 - acc: 0.5996 - val_loss: 0.6743 - val_acc: 0.5776\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6779 - acc: 0.5812 - val_loss: 0.6690 - val_acc: 0.5836\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6733 - acc: 0.5828 - val_loss: 0.6798 - val_acc: 0.5836\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6803 - acc: 0.5724 - val_loss: 0.6716 - val_acc: 0.6280\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6731 - acc: 0.5852 - val_loss: 0.6618 - val_acc: 0.6332\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6676 - acc: 0.5940 - val_loss: 0.6626 - val_acc: 0.6240\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6703 - acc: 0.5952 - val_loss: 0.6641 - val_acc: 0.6188\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6660 - acc: 0.5960 - val_loss: 0.6600 - val_acc: 0.6324\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6647 - acc: 0.5960 - val_loss: 0.6645 - val_acc: 0.6024\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6690 - acc: 0.5868 - val_loss: 0.6701 - val_acc: 0.6088\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6777 - acc: 0.5732 - val_loss: 0.6823 - val_acc: 0.5784\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6772 - acc: 0.5616 - val_loss: 0.6723 - val_acc: 0.6092\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6699 - acc: 0.5884 - val_loss: 0.6606 - val_acc: 0.6244\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6774 - acc: 0.5736 - val_loss: 0.6743 - val_acc: 0.6112\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6695 - acc: 0.5872 - val_loss: 0.6557 - val_acc: 0.6368\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6691 - acc: 0.5972 - val_loss: 0.6697 - val_acc: 0.6056\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6736 - acc: 0.5808 - val_loss: 0.6682 - val_acc: 0.6100\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6742 - acc: 0.5816 - val_loss: 0.6750 - val_acc: 0.5844\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6790 - acc: 0.5764 - val_loss: 0.6676 - val_acc: 0.6272\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6733 - acc: 0.5788 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6771 - acc: 0.5840 - val_loss: 0.6640 - val_acc: 0.6280\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6737 - acc: 0.5924 - val_loss: 0.6684 - val_acc: 0.5964\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6738 - acc: 0.5872 - val_loss: 0.6688 - val_acc: 0.5856\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6771 - acc: 0.5748 - val_loss: 0.6742 - val_acc: 0.6156\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6737 - acc: 0.5848 - val_loss: 0.6593 - val_acc: 0.6304\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6589 - acc: 0.6168 - val_loss: 0.6542 - val_acc: 0.6340\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6662 - acc: 0.6024 - val_loss: 0.6772 - val_acc: 0.5712\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6734 - acc: 0.5848 - val_loss: 0.6719 - val_acc: 0.5840\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6744 - acc: 0.5748 - val_loss: 0.6800 - val_acc: 0.5916\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6733 - acc: 0.5852 - val_loss: 0.6616 - val_acc: 0.6208\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6705 - acc: 0.5936 - val_loss: 0.6685 - val_acc: 0.6020\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6658 - acc: 0.5816 - val_loss: 0.6632 - val_acc: 0.6052\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6720 - acc: 0.5908 - val_loss: 0.6809 - val_acc: 0.5436\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6897 - acc: 0.5612 - val_loss: 0.6772 - val_acc: 0.6140\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.5944 - val_loss: 0.6703 - val_acc: 0.6204\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6717 - acc: 0.5948 - val_loss: 0.6644 - val_acc: 0.6268\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6682 - acc: 0.5916 - val_loss: 0.6645 - val_acc: 0.6276\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - acc: 0.5936 - val_loss: 0.6632 - val_acc: 0.6072\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6682 - acc: 0.5956 - val_loss: 0.6568 - val_acc: 0.6248\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6841 - acc: 0.5872 - val_loss: 0.6796 - val_acc: 0.5628\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6751 - acc: 0.5660 - val_loss: 0.6729 - val_acc: 0.6264\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6741 - acc: 0.5820 - val_loss: 0.6613 - val_acc: 0.6276\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6728 - acc: 0.5900 - val_loss: 0.6787 - val_acc: 0.5396\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - acc: 0.5552 - val_loss: 0.6987 - val_acc: 0.5220\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7013 - acc: 0.5604 - val_loss: 0.6720 - val_acc: 0.5892\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6792 - acc: 0.5864 - val_loss: 0.6765 - val_acc: 0.6196\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6701 - acc: 0.6000 - val_loss: 0.6649 - val_acc: 0.6220\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6701 - acc: 0.5828 - val_loss: 0.6688 - val_acc: 0.6132\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6739 - acc: 0.5892 - val_loss: 0.6605 - val_acc: 0.6292\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6645 - acc: 0.5980 - val_loss: 0.6769 - val_acc: 0.6124\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6997 - acc: 0.5900 - val_loss: 0.6617 - val_acc: 0.6260\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6659 - acc: 0.6000 - val_loss: 0.6677 - val_acc: 0.6104\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6658 - acc: 0.5864 - val_loss: 0.6581 - val_acc: 0.6260\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6654 - acc: 0.6048 - val_loss: 0.6655 - val_acc: 0.6180\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6730 - acc: 0.5880 - val_loss: 0.6610 - val_acc: 0.6280\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6647 - acc: 0.6028 - val_loss: 0.6649 - val_acc: 0.6116\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6731 - acc: 0.5872 - val_loss: 0.6617 - val_acc: 0.6184\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6668 - acc: 0.5976 - val_loss: 0.6719 - val_acc: 0.6020\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6765 - acc: 0.5692 - val_loss: 0.6666 - val_acc: 0.6284\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - acc: 0.5928 - val_loss: 0.6613 - val_acc: 0.6336\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6687 - acc: 0.6008 - val_loss: 0.6658 - val_acc: 0.6096\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6707 - acc: 0.5928 - val_loss: 0.6631 - val_acc: 0.6124\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6760 - acc: 0.5760 - val_loss: 0.6786 - val_acc: 0.5620\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6737 - acc: 0.5592 - val_loss: 0.6675 - val_acc: 0.6228\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6694 - acc: 0.5996 - val_loss: 0.6622 - val_acc: 0.6244\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6673 - acc: 0.5988 - val_loss: 0.6671 - val_acc: 0.6056\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6754 - acc: 0.5828 - val_loss: 0.6652 - val_acc: 0.6144\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6798 - acc: 0.5900 - val_loss: 0.6799 - val_acc: 0.5692\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6795 - acc: 0.5612 - val_loss: 0.6757 - val_acc: 0.5764\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6775 - acc: 0.5776 - val_loss: 0.6694 - val_acc: 0.5940\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6789 - acc: 0.5788 - val_loss: 0.6686 - val_acc: 0.6092\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6774 - acc: 0.5688 - val_loss: 0.6787 - val_acc: 0.5832\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6739 - acc: 0.5736 - val_loss: 0.6626 - val_acc: 0.6156\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6720 - acc: 0.5932 - val_loss: 0.6670 - val_acc: 0.6084\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6653 - acc: 0.5944 - val_loss: 0.6573 - val_acc: 0.6256\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6651 - acc: 0.6016 - val_loss: 0.6696 - val_acc: 0.6024\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.5836 - val_loss: 0.6661 - val_acc: 0.6104\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6699 - acc: 0.5960 - val_loss: 0.6720 - val_acc: 0.5924\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6776 - acc: 0.5756 - val_loss: 0.6717 - val_acc: 0.6156\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6798 - acc: 0.5776 - val_loss: 0.6691 - val_acc: 0.6212\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6696 - acc: 0.5988 - val_loss: 0.6609 - val_acc: 0.6288\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6649 - acc: 0.6028 - val_loss: 0.6611 - val_acc: 0.6276\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6732 - acc: 0.5884 - val_loss: 0.6665 - val_acc: 0.6220\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6695 - acc: 0.5924 - val_loss: 0.6612 - val_acc: 0.6212\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6660 - acc: 0.6140 - val_loss: 0.6679 - val_acc: 0.5960\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6722 - acc: 0.5836 - val_loss: 0.6825 - val_acc: 0.5700\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7069 - acc: 0.5772 - val_loss: 0.6798 - val_acc: 0.5676\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6777 - acc: 0.5660 - val_loss: 0.6746 - val_acc: 0.6236\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6742 - acc: 0.5864 - val_loss: 0.6627 - val_acc: 0.6320\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6684 - acc: 0.5948 - val_loss: 0.6640 - val_acc: 0.6324\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.5804 - val_loss: 0.6637 - val_acc: 0.6320\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6677 - acc: 0.5852 - val_loss: 0.6866 - val_acc: 0.5992\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7072 - acc: 0.5852 - val_loss: 0.6734 - val_acc: 0.5704\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6990 - acc: 0.5612 - val_loss: 0.6803 - val_acc: 0.5468\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6831 - acc: 0.5668 - val_loss: 0.6816 - val_acc: 0.6028\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6772 - acc: 0.5856 - val_loss: 0.6687 - val_acc: 0.6112\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6703 - acc: 0.5928 - val_loss: 0.6644 - val_acc: 0.6348\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6064 - val_loss: 0.6615 - val_acc: 0.6204\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6692 - acc: 0.5920 - val_loss: 0.6655 - val_acc: 0.6152\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6765 - acc: 0.5772 - val_loss: 0.6692 - val_acc: 0.6256\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6728 - acc: 0.5784 - val_loss: 0.6671 - val_acc: 0.6268\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6707 - acc: 0.5952 - val_loss: 0.6633 - val_acc: 0.6116\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6654 - acc: 0.5984 - val_loss: 0.6614 - val_acc: 0.6240\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6694 - acc: 0.5912 - val_loss: 0.6658 - val_acc: 0.6048\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - acc: 0.5960 - val_loss: 0.6669 - val_acc: 0.6100\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6717 - acc: 0.5876 - val_loss: 0.6800 - val_acc: 0.5544\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6785 - acc: 0.5768 - val_loss: 0.6707 - val_acc: 0.6172\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.6661 - val_acc: 0.6072\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - acc: 0.5848 - val_loss: 0.6643 - val_acc: 0.6232\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6652 - acc: 0.5836 - val_loss: 0.6660 - val_acc: 0.6104\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6683 - acc: 0.5860 - val_loss: 0.6669 - val_acc: 0.6180\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6644 - acc: 0.5892 - val_loss: 0.6635 - val_acc: 0.6188\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6741 - acc: 0.5948 - val_loss: 0.6682 - val_acc: 0.6312\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6779 - acc: 0.5892 - val_loss: 0.6617 - val_acc: 0.6300\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6780 - acc: 0.5652 - val_loss: 0.6717 - val_acc: 0.6008\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6739 - acc: 0.5820 - val_loss: 0.6674 - val_acc: 0.6208\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.5708 - val_loss: 0.6719 - val_acc: 0.5904\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6720 - acc: 0.5868 - val_loss: 0.6657 - val_acc: 0.6152\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6797 - acc: 0.5860 - val_loss: 0.6785 - val_acc: 0.5652\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6824 - acc: 0.5700 - val_loss: 0.6733 - val_acc: 0.6200\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6717 - acc: 0.5840 - val_loss: 0.6650 - val_acc: 0.6144\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.5876 - val_loss: 0.6629 - val_acc: 0.6176\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6737 - acc: 0.5848 - val_loss: 0.6712 - val_acc: 0.5980\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6788 - acc: 0.5804 - val_loss: 0.6736 - val_acc: 0.6192\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6781 - acc: 0.5780 - val_loss: 0.6720 - val_acc: 0.6304\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6717 - acc: 0.5972 - val_loss: 0.6598 - val_acc: 0.6244\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6639 - acc: 0.5928 - val_loss: 0.6611 - val_acc: 0.6180\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6700 - acc: 0.5896 - val_loss: 0.6649 - val_acc: 0.6256\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6701 - acc: 0.5792 - val_loss: 0.6687 - val_acc: 0.6064\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6667 - acc: 0.5884 - val_loss: 0.6777 - val_acc: 0.5472\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6986 - acc: 0.5628 - val_loss: 0.7200 - val_acc: 0.4960\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7306 - acc: 0.5272 - val_loss: 0.6844 - val_acc: 0.5844\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6802 - acc: 0.5788 - val_loss: 0.6762 - val_acc: 0.6152\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6747 - acc: 0.5832 - val_loss: 0.6707 - val_acc: 0.6240\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6748 - acc: 0.6036 - val_loss: 0.6691 - val_acc: 0.6272\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6729 - acc: 0.5796 - val_loss: 0.6695 - val_acc: 0.6288\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6668 - acc: 0.5984 - val_loss: 0.6591 - val_acc: 0.6228\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.6004 - val_loss: 0.6697 - val_acc: 0.6076\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6687 - acc: 0.5900 - val_loss: 0.6591 - val_acc: 0.6264\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6024 - val_loss: 0.6708 - val_acc: 0.5992\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6684 - acc: 0.5864 - val_loss: 0.6575 - val_acc: 0.6296\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6621 - acc: 0.5964 - val_loss: 0.6670 - val_acc: 0.6092\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6739 - acc: 0.5752 - val_loss: 0.6628 - val_acc: 0.6272\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6751 - acc: 0.5872 - val_loss: 0.6708 - val_acc: 0.6192\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6692 - acc: 0.5912 - val_loss: 0.6588 - val_acc: 0.6340\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6673 - acc: 0.5872 - val_loss: 0.6682 - val_acc: 0.5956\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6769 - acc: 0.5728 - val_loss: 0.6660 - val_acc: 0.6236\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6756 - acc: 0.5864 - val_loss: 0.6724 - val_acc: 0.5900\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6715 - acc: 0.5804 - val_loss: 0.6601 - val_acc: 0.6248\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6706 - acc: 0.5808 - val_loss: 0.6695 - val_acc: 0.6044\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6707 - acc: 0.5904 - val_loss: 0.6634 - val_acc: 0.6096\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6757 - acc: 0.5856 - val_loss: 0.6780 - val_acc: 0.5580\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6745 - acc: 0.5724 - val_loss: 0.6685 - val_acc: 0.6340\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.5888 - val_loss: 0.6626 - val_acc: 0.6216\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6688 - acc: 0.5992 - val_loss: 0.6597 - val_acc: 0.6296\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6707 - acc: 0.5876 - val_loss: 0.6736 - val_acc: 0.5816\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6681 - acc: 0.5948 - val_loss: 0.6595 - val_acc: 0.6252\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6740 - acc: 0.5868 - val_loss: 0.6731 - val_acc: 0.6004\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6807 - acc: 0.5804 - val_loss: 0.6868 - val_acc: 0.5240\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7034 - acc: 0.5424 - val_loss: 0.6816 - val_acc: 0.5516\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6800 - acc: 0.5724 - val_loss: 0.6737 - val_acc: 0.6216\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.5928 - val_loss: 0.6674 - val_acc: 0.6368\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6672 - acc: 0.5956 - val_loss: 0.6585 - val_acc: 0.6340\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6592 - acc: 0.6068 - val_loss: 0.6565 - val_acc: 0.6292\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6641 - acc: 0.5988 - val_loss: 0.6701 - val_acc: 0.5920\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6739 - acc: 0.5868 - val_loss: 0.6629 - val_acc: 0.6152\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6683 - acc: 0.5964 - val_loss: 0.6690 - val_acc: 0.5988\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.5960 - val_loss: 0.6612 - val_acc: 0.6188\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6705 - acc: 0.6048 - val_loss: 0.6743 - val_acc: 0.5888\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6730 - acc: 0.6004 - val_loss: 0.6641 - val_acc: 0.6044\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6773 - acc: 0.5808 - val_loss: 0.6756 - val_acc: 0.5844\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6710 - acc: 0.5744 - val_loss: 0.6677 - val_acc: 0.6180\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.5984 - val_loss: 0.6619 - val_acc: 0.6244\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6725 - acc: 0.5964 - val_loss: 0.6752 - val_acc: 0.5724\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6892 - acc: 0.5572 - val_loss: 0.6831 - val_acc: 0.5532\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6820 - acc: 0.5712 - val_loss: 0.6703 - val_acc: 0.5916\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6760 - acc: 0.5816 - val_loss: 0.6782 - val_acc: 0.6172\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6727 - acc: 0.5936 - val_loss: 0.6673 - val_acc: 0.6216\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6835 - acc: 0.5656 - val_loss: 0.6700 - val_acc: 0.6088\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - acc: 0.5956 - val_loss: 0.6623 - val_acc: 0.6276\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6685 - acc: 0.5952 - val_loss: 0.6666 - val_acc: 0.6136\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6724 - acc: 0.5912 - val_loss: 0.6637 - val_acc: 0.6292\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6704 - acc: 0.5864 - val_loss: 0.6726 - val_acc: 0.6100\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5960 - val_loss: 0.6610 - val_acc: 0.6236\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.5864 - val_loss: 0.6722 - val_acc: 0.5932\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6716 - acc: 0.5888 - val_loss: 0.6638 - val_acc: 0.6136\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.5928 - val_loss: 0.6722 - val_acc: 0.5864\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6723 - acc: 0.5940 - val_loss: 0.6644 - val_acc: 0.6112\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6775 - acc: 0.5992 - val_loss: 0.6762 - val_acc: 0.5852\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6770 - acc: 0.5624 - val_loss: 0.6701 - val_acc: 0.6316\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.5876 - val_loss: 0.6621 - val_acc: 0.6372\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6656 - acc: 0.5884 - val_loss: 0.6687 - val_acc: 0.5960\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6683 - acc: 0.5916 - val_loss: 0.6650 - val_acc: 0.6060\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.5848 - val_loss: 0.6781 - val_acc: 0.5788\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6717 - acc: 0.5872 - val_loss: 0.6664 - val_acc: 0.6340\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6693 - acc: 0.5836 - val_loss: 0.6852 - val_acc: 0.5996\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7035 - acc: 0.5724 - val_loss: 0.6670 - val_acc: 0.6220\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6704 - acc: 0.5880 - val_loss: 0.6677 - val_acc: 0.6132\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6684 - acc: 0.5996 - val_loss: 0.6627 - val_acc: 0.6272\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.5924 - val_loss: 0.6702 - val_acc: 0.6032\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6656 - acc: 0.5976 - val_loss: 0.6608 - val_acc: 0.6268\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6688 - acc: 0.6016 - val_loss: 0.6752 - val_acc: 0.5776\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6790 - acc: 0.5812 - val_loss: 0.6739 - val_acc: 0.5988\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6827 - acc: 0.5712 - val_loss: 0.6802 - val_acc: 0.6076\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6724 - acc: 0.5884 - val_loss: 0.6638 - val_acc: 0.6344\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6734 - acc: 0.5996 - val_loss: 0.6601 - val_acc: 0.6320\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6648 - acc: 0.6092 - val_loss: 0.6549 - val_acc: 0.6336\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6670 - acc: 0.5980 - val_loss: 0.6687 - val_acc: 0.6124\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.5972 - val_loss: 0.6623 - val_acc: 0.6280\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6680 - acc: 0.6016 - val_loss: 0.6694 - val_acc: 0.5984\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6667 - acc: 0.5944 - val_loss: 0.6692 - val_acc: 0.5860\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6908 - acc: 0.5760 - val_loss: 0.6825 - val_acc: 0.5392\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6862 - acc: 0.5576 - val_loss: 0.6832 - val_acc: 0.6140\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6766 - acc: 0.5980 - val_loss: 0.6702 - val_acc: 0.6264\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6716 - acc: 0.5888 - val_loss: 0.6635 - val_acc: 0.6332\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6677 - acc: 0.5888 - val_loss: 0.6614 - val_acc: 0.6244\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6619 - acc: 0.6084 - val_loss: 0.6567 - val_acc: 0.6356\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6680 - acc: 0.5916 - val_loss: 0.6703 - val_acc: 0.5904\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.5800 - val_loss: 0.6675 - val_acc: 0.6072\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6746 - acc: 0.5652 - val_loss: 0.6698 - val_acc: 0.6120\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6720 - acc: 0.5784 - val_loss: 0.6655 - val_acc: 0.6224\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5984 - val_loss: 0.6666 - val_acc: 0.6144\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6669 - acc: 0.5932 - val_loss: 0.6590 - val_acc: 0.6256\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6728 - acc: 0.5884 - val_loss: 0.6700 - val_acc: 0.6036\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6734 - acc: 0.5836 - val_loss: 0.6651 - val_acc: 0.6284\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6763 - acc: 0.5900 - val_loss: 0.6720 - val_acc: 0.6120\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - acc: 0.6040 - val_loss: 0.6559 - val_acc: 0.6320\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6742 - acc: 0.5864 - val_loss: 0.6723 - val_acc: 0.6052\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6705 - acc: 0.5824 - val_loss: 0.6623 - val_acc: 0.6320\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6647 - acc: 0.6060 - val_loss: 0.6593 - val_acc: 0.6280\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6688 - acc: 0.5984 - val_loss: 0.6630 - val_acc: 0.6316\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6651 - acc: 0.5988 - val_loss: 0.6604 - val_acc: 0.6320\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6768 - acc: 0.5864 - val_loss: 0.6678 - val_acc: 0.6384\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6717 - acc: 0.5796 - val_loss: 0.6593 - val_acc: 0.6200\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - acc: 0.5924 - val_loss: 0.6616 - val_acc: 0.6352\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6656 - acc: 0.5856 - val_loss: 0.6680 - val_acc: 0.5960\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6785 - acc: 0.5752 - val_loss: 0.6725 - val_acc: 0.5776\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6844 - acc: 0.5632 - val_loss: 0.6868 - val_acc: 0.5936\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6759 - acc: 0.5908 - val_loss: 0.6643 - val_acc: 0.6268\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6698 - acc: 0.5920 - val_loss: 0.6653 - val_acc: 0.6068\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721 - acc: 0.5804 - val_loss: 0.6709 - val_acc: 0.6232\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - acc: 0.5968 - val_loss: 0.6628 - val_acc: 0.6264\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6673 - acc: 0.5900 - val_loss: 0.6611 - val_acc: 0.6248\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - acc: 0.5972 - val_loss: 0.6651 - val_acc: 0.6096\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6776 - acc: 0.5812 - val_loss: 0.6686 - val_acc: 0.6120\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6741 - acc: 0.6032 - val_loss: 0.6694 - val_acc: 0.6008\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6669 - acc: 0.5948 - val_loss: 0.6694 - val_acc: 0.5784\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6887 - acc: 0.5692 - val_loss: 0.6805 - val_acc: 0.5516\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6771 - acc: 0.5540 - val_loss: 0.6767 - val_acc: 0.6060\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6775 - acc: 0.5740 - val_loss: 0.6667 - val_acc: 0.6364\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6693 - acc: 0.5876 - val_loss: 0.6610 - val_acc: 0.6328\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6695 - acc: 0.5960 - val_loss: 0.6630 - val_acc: 0.6336\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6747 - acc: 0.5724 - val_loss: 0.6688 - val_acc: 0.6068\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6749 - acc: 0.5716 - val_loss: 0.6712 - val_acc: 0.6244\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6720 - acc: 0.5904 - val_loss: 0.6632 - val_acc: 0.6272\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6671 - acc: 0.5960 - val_loss: 0.6587 - val_acc: 0.6340\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6699 - acc: 0.5888 - val_loss: 0.6656 - val_acc: 0.6176\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6679 - acc: 0.6080 - val_loss: 0.6589 - val_acc: 0.6248\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6792 - acc: 0.5800 - val_loss: 0.6761 - val_acc: 0.6184\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6731 - acc: 0.5892 - val_loss: 0.6587 - val_acc: 0.6344\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6696 - acc: 0.5856 - val_loss: 0.6624 - val_acc: 0.6256\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6663 - acc: 0.5940 - val_loss: 0.6889 - val_acc: 0.5304\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7302 - acc: 0.5488 - val_loss: 0.8292 - val_acc: 0.4876\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8420 - acc: 0.5088 - val_loss: 0.6857 - val_acc: 0.5608\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6813 - acc: 0.5636 - val_loss: 0.6767 - val_acc: 0.6236\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6751 - acc: 0.5768 - val_loss: 0.6686 - val_acc: 0.6300\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6691 - acc: 0.5848 - val_loss: 0.6635 - val_acc: 0.6324\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6768 - acc: 0.5864 - val_loss: 0.6661 - val_acc: 0.6324\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6666 - acc: 0.5948 - val_loss: 0.6584 - val_acc: 0.6304\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6781 - acc: 0.5828 - val_loss: 0.6714 - val_acc: 0.6128\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6691 - acc: 0.5856 - val_loss: 0.6625 - val_acc: 0.6324\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6655 - acc: 0.6000 - val_loss: 0.6596 - val_acc: 0.6340\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6614 - acc: 0.6024 - val_loss: 0.6591 - val_acc: 0.6344\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6674 - acc: 0.5976 - val_loss: 0.6641 - val_acc: 0.6220\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6653 - acc: 0.5924 - val_loss: 0.6574 - val_acc: 0.6244\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6693 - acc: 0.5956 - val_loss: 0.6654 - val_acc: 0.6164\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6680 - acc: 0.5944 - val_loss: 0.6589 - val_acc: 0.6264\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6758 - acc: 0.5844 - val_loss: 0.6708 - val_acc: 0.6152\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6660 - acc: 0.5948 - val_loss: 0.6572 - val_acc: 0.6352\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6638 - acc: 0.5876 - val_loss: 0.6645 - val_acc: 0.6104\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6657 - acc: 0.5968 - val_loss: 0.6574 - val_acc: 0.6260\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6731 - acc: 0.5856 - val_loss: 0.6757 - val_acc: 0.5836\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6772 - acc: 0.5660 - val_loss: 0.6657 - val_acc: 0.6344\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6698 - acc: 0.5916 - val_loss: 0.6606 - val_acc: 0.6272\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6617 - acc: 0.6092 - val_loss: 0.6547 - val_acc: 0.6368\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6775 - acc: 0.5776 - val_loss: 0.6731 - val_acc: 0.6016\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - acc: 0.5808 - val_loss: 0.6637 - val_acc: 0.6252\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6605 - acc: 0.6096 - val_loss: 0.6583 - val_acc: 0.6220\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6759 - acc: 0.5988 - val_loss: 0.6654 - val_acc: 0.6176\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.5828 - val_loss: 0.6712 - val_acc: 0.6000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6759 - acc: 0.5760 - val_loss: 0.6667 - val_acc: 0.6104\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6763 - acc: 0.5824 - val_loss: 0.6702 - val_acc: 0.6196\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6722 - acc: 0.5916 - val_loss: 0.6628 - val_acc: 0.6212\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - acc: 0.5996 - val_loss: 0.6621 - val_acc: 0.6232\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6735 - acc: 0.5884 - val_loss: 0.6677 - val_acc: 0.6292\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6705 - acc: 0.5916 - val_loss: 0.6595 - val_acc: 0.6204\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6611 - acc: 0.6060 - val_loss: 0.6564 - val_acc: 0.6356\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6756 - acc: 0.5876 - val_loss: 0.6721 - val_acc: 0.6344\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6657 - acc: 0.6016 - val_loss: 0.6696 - val_acc: 0.6112\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6951 - acc: 0.5776 - val_loss: 0.6931 - val_acc: 0.5164\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6993 - acc: 0.5444 - val_loss: 0.6829 - val_acc: 0.6264\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6791 - acc: 0.5808 - val_loss: 0.6724 - val_acc: 0.6048\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6730 - acc: 0.5908 - val_loss: 0.6744 - val_acc: 0.6144\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6687 - acc: 0.6080 - val_loss: 0.6586 - val_acc: 0.6188\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6780 - acc: 0.5924 - val_loss: 0.6749 - val_acc: 0.5936\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6770 - acc: 0.5660 - val_loss: 0.6684 - val_acc: 0.6244\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6747 - acc: 0.5864 - val_loss: 0.6706 - val_acc: 0.6120\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6744 - acc: 0.5732 - val_loss: 0.6625 - val_acc: 0.6364\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6678 - acc: 0.6016 - val_loss: 0.6633 - val_acc: 0.6176\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.5792 - val_loss: 0.6634 - val_acc: 0.6348\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6718 - acc: 0.5916 - val_loss: 0.6645 - val_acc: 0.6208\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6655 - acc: 0.5944 - val_loss: 0.6609 - val_acc: 0.6256\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.5952 - val_loss: 0.6642 - val_acc: 0.6288\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6729 - acc: 0.5820 - val_loss: 0.6641 - val_acc: 0.6296\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6682 - acc: 0.5956 - val_loss: 0.6640 - val_acc: 0.6088\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6724 - acc: 0.5892 - val_loss: 0.6625 - val_acc: 0.6328\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6689 - acc: 0.5856 - val_loss: 0.6691 - val_acc: 0.5936\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6772 - acc: 0.5800 - val_loss: 0.6696 - val_acc: 0.6204\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6767 - acc: 0.5828 - val_loss: 0.6780 - val_acc: 0.5752\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6802 - acc: 0.5644 - val_loss: 0.6704 - val_acc: 0.6260\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - acc: 0.5880 - val_loss: 0.6583 - val_acc: 0.6312\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6721 - acc: 0.5816 - val_loss: 0.6611 - val_acc: 0.6252\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6669 - acc: 0.6000 - val_loss: 0.6664 - val_acc: 0.6124\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6735 - acc: 0.5728 - val_loss: 0.6656 - val_acc: 0.6080\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - acc: 0.5716 - val_loss: 0.6842 - val_acc: 0.5352\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6837 - acc: 0.5588 - val_loss: 0.6771 - val_acc: 0.6208\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6720 - acc: 0.5892 - val_loss: 0.6641 - val_acc: 0.6272\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6693 - acc: 0.5992 - val_loss: 0.6657 - val_acc: 0.6112\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.5904 - val_loss: 0.6638 - val_acc: 0.6324\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6645 - acc: 0.6060 - val_loss: 0.6545 - val_acc: 0.6336\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.5868 - val_loss: 0.6726 - val_acc: 0.5992\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6761 - acc: 0.5772 - val_loss: 0.6676 - val_acc: 0.6052\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6734 - acc: 0.6032 - val_loss: 0.6721 - val_acc: 0.5888\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6674 - acc: 0.5920 - val_loss: 0.6673 - val_acc: 0.5976\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6752 - acc: 0.5952 - val_loss: 0.6776 - val_acc: 0.5632\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6806 - acc: 0.5716 - val_loss: 0.6694 - val_acc: 0.6276\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6690 - acc: 0.6156 - val_loss: 0.6571 - val_acc: 0.6332\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6653 - acc: 0.6108 - val_loss: 0.6597 - val_acc: 0.6296\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.5892 - val_loss: 0.6671 - val_acc: 0.6272\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6668 - acc: 0.5992 - val_loss: 0.6581 - val_acc: 0.6312\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6718 - acc: 0.5828 - val_loss: 0.6701 - val_acc: 0.6088\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.5800 - val_loss: 0.6623 - val_acc: 0.6272\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6666 - acc: 0.5840 - val_loss: 0.6634 - val_acc: 0.6152\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6751 - acc: 0.5784 - val_loss: 0.6695 - val_acc: 0.6216\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6752 - acc: 0.5780 - val_loss: 0.6701 - val_acc: 0.6072\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6699 - acc: 0.5812 - val_loss: 0.6669 - val_acc: 0.6144\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6715 - acc: 0.5760 - val_loss: 0.6659 - val_acc: 0.6208\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6719 - acc: 0.5844 - val_loss: 0.6686 - val_acc: 0.6064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a50d61d0a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "loader_tr = SingleLoader(dataset)\n",
    "loader_va = SingleLoader(dataset_va)\n",
    "model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data = loader_va.load(),\n",
    "    validation_steps = loader_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115f9ef",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82781529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model.\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6604 - acc: 0.6260\n",
      "Done.\n",
      "Test loss: 0.660412609577179\n",
      "Test accuracy: 0.6259999871253967\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset_te)\n",
    "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bc5f4233-f3dc-4b83-9c8e-fedafeb73041",
    "3b7e1cb4-9f77-4a43-8162-24cc7cd0808a",
    "869dbe34-05f0-4a8a-b4e8-e4efd504986a",
    "6ba369a2-7dfc-462a-a769-8a5d1bc73a4f",
    "1ed0968c-139e-49ef-ba57-0c9f0c979f72"
   ],
   "name": "MainNotebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "73e43853552d6fc356b2c05e3ac4c7e6c4dba3aed2cbc26a744008cb0f5a4666"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
